{
  "name": "elasticsearch Chef cookbook",
  "chef_cookbook_name": "elasticsearch",
  "revision": "0.2.5",
  "uris": [
    "https://supermarket.chef.io/cookbooks/elasticsearch",
    "https://supermarket.chef.io/cookbooks/elasticsearch/download",
    "https://supermarket.chef.io/cookbooks/elasticsearch/versions/0.2.5",
    "https://supermarket.chef.io/cookbooks/elasticsearch/versions/0.2.5/download",
    "https://supermarket.chef.io/api/v1/cookbooks/elasticsearch/versions/0.2.5",
    "https://supermarket.chef.io/api/v1/cookbooks/elasticsearch",
    "https://supermarket.chef.io/api/v1/cookbooks/elasticsearch/versions/0.2.5/download"
  ],
  "labels": [
    "Chef cookbook",
    "Other",
    "Executable/Script/Chef Cookbook",
    "Mode/Executable/Script/Chef Cookbook",
    "Type/Middleware/Search/Elasticsearch"
  ],
  "info_url": "https://supermarket.chef.io/cookbooks/elasticsearch",
  "package_url": "https://supermarket.chef.io/api/v1/cookbooks/elasticsearch/versions/0.2.5/download",
  "deprecated": false,
  "created": "2010-06-28T20:57:57.000Z",
  "updated": "2016-10-12T10:47:15.640Z",
  "description": "Installs and configures Elasticsearch",
  "maintainer": {
    "name": "elastic",
    "email": "karmi@karmi.cz"
  },
  "license": "Apache",
  "chef_foodcritic_failure": true,
  "chef_up_for_adoption": null,
  "rating": null,
  "followers_count": 147,
  "downloads_count": 27656375,
  "downloads_count_revision": 1264982,
  "repository_url": "https://github.com/elasticsearch/cookbook-elasticsearch",
  "issues_url": "https://github.com/elasticsearch/cookbook-elasticsearch",
  "chef_source_url": "https://github.com/elasticsearch/cookbook-elasticsearch",
  "gatherbase_origin": "chef-supermarket",
  "readme": "Description\n-----------\n\nThis _Chef_ cookbook installs and configures the [_Elasticsearch_](http://www.elasticsearch.org)\nsearch engine on a Linux compatible operating system.\n\n-----\n### Important Upgrade Notice ###\n\nAs of version 0.2.0, the Elasticsearch cookbook available from the Opscode community site is no longer\ncompatible with the previous version. If you are a user of the previous cookbook, please be aware that\nthere is no recommended upgrade process and you have to actively test the upgrade in your environment.\nIf you have questions, please leave a message in the comments section on the community site. Thanks!\n\n-----\n\nIt requires a working _Java_ installation on the target node; add your preferred `java` cookbook to the node `run_list`.\n\nThe cookbook downloads the _elasticsearch_ tarball (via the [`ark`](http://github.com/bryanwb/chef-ark) provider),\nunpacks and moves it to the directory you have specified in the node configuration (`/usr/local/elasticsearch` by default).\n\nIt installs a service which enables you to start, stop, restart and check status of the _elasticsearch_ process.\n\nIf you include the `elasticsearch::monit` recipe, it will create a configuration file for _Monit_,\nwhich will check whether _elasticsearch_ is running, reachable by HTTP and the cluster is in the \"green\" state.\n(Assumed you have included a compatible [\"monit\" cookbook](http://community.opscode.com/cookbooks/monit)\nin your run list first.)\n\nIf you include the `elasticsearch::aws` recipe, the\n[AWS Cloud Plugin](http://github.com/elasticsearch/elasticsearch-cloud-aws) will be installed on the node,\nallowing you to use the _Amazon_ AWS-related features (node auto-discovery, etc).\nSet your AWS credentials either in the \"elasticsearch/aws\" data bag, or directly in the role/node configuration.\n\nIf you include the `elasticsearch::data` and `elasticsearch::ebs` recipes, an EBS volume will be automatically\ncreated, formatted and mounted so you can use it as a local gateway for _Elasticsearch_.\nWhen the EBS configuration contains a `snapshot_id` value, it will be created with data from the corresponding snapshot. See the `attributes/data` file for more information.\n\nIf you include the `elasticsearch::proxy` recipe, it will configure the _Nginx_ server as\na reverse proxy for _Elasticsearch_, so you may access it remotely with HTTP authentication.\nSet the credentials either in a \"elasticsearch/users\" data bag, or directly in the role/node configuration.\n\n\nUsage\n-----\n\nFor an overview, please read the tutorial on\n[deploying elasticsearch with _Chef Solo_](http://www.elasticsearch.org/tutorials/2012/03/21/deploying-elasticsearch-with-chef-solo.html)\nwhich uses this cookbook.\n\nFor _Chef Server_ based deployment, include the recipes you want to be executed in a\ndedicated `elasticsearch` role, or in the node `run_list`.\n\nThen, upload the cookbook to the _Chef_ server:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    knife cookbook upload elasticsearch\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo enable the _Amazon_ AWS related features, include the `elasticsearch::aws` recipe.\nYou will need to configure the AWS credentials.\n\nYou may do that in the node configuration (with `knife node edit MYNODE` or in the _Chef Server_ console),\nin a role with `override_attributes` declaration, but it is arguably most convenient to store\nthe information in an \"elasticsearch\" _data bag_:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    mkdir -p ./data_bags/elasticsearch\n    echo '{\n      \"id\" : \"aws\",\n      \"_default\" : {\n        \"discovery\" : { \"type\": \"ec2\" },\n\n        \"cloud\"   : {\n          \"aws\"     : { \"access_key\": \"YOUR ACCESS KEY\", \"secret_key\": \"YOUR SECRET ACCESS KEY\" },\n          \"ec2\"     : { \"security_group\": \"elasticsearch\" }\n        }\n      }\n    }' >> ./data_bags/elasticsearch/aws.json\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nDo not forget to upload the data bag to the _Chef_ server:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    knife data bag from file elasticsearch aws.json\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo use the EBS related features, use your preferred method of configuring node attributes,\nor store the configuration in a data bag called `elasticsearch/data`:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~json\n    {\n      \"elasticsearch\": {\n        // ...\n        \"data\" : {\n          \"devices\" : {\n            \"/dev/sda2\" : {\n              \"file_system\"      : \"ext3\",\n              \"mount_options\"    : \"rw,user\",\n              \"mount_path\"       : \"/usr/local/var/data/elasticsearch/disk1\",\n              \"format_command\"   : \"mkfs.ext3\",\n              \"fs_check_command\" : \"dumpe2fs\",\n              \"ebs\"            : {\n                \"size\"                  : 250,         // In GB\n                \"delete_on_termination\" : true,\n                \"type\"                  : \"io1\",\n                \"iops\"                  : 2000\n              }\n            }\n          }\n        }\n      }\n    }\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nUsually, you will restrict the access to _Elasticsearch_ with firewall rules. However, it's convenient\nto be able to connect to the _Elasticsearch_ cluster from `curl` or a HTTP client, or to use a\nmanagement tool such as [_BigDesk_](http://github.com/lukas-vlcek/bigdesk) or\n[_Paramedic_](http://github.com/karmi/elasticsearch-paramedic).\n(Don't forget to set the `node.elasticsearch[:nginx][:allow_cluster_api]` attribute to _true_\nif you want to access these tools via the proxy.)\n\nTo enable authorized access to _elasticsearch_, you need to include the `elasticsearch::proxy` recipe,\nwhich will install, configure and run [_Nginx_](http://nginx.org) as a reverse proxy, allowing users with proper\ncredentials to connect.\n\nUsernames and passwords may be stored in a data bag `elasticsearch/users`:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    mkdir -p ./data_bags/elasticsearch\n    echo '{\n      \"id\" : \"users\",\n      \"_default\" : {\n        \"users\" : [\n          {\"username\" : \"USERNAME\", \"password\" : \"PASSWORD\"},\n          {\"username\" : \"USERNAME\", \"password\" : \"PASSWORD\"}\n        ]\n      }\n    }\n    ' >> ./data_bags/elasticsearch/users.json\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAgain, do not forget to upload the data bag to the _Chef_ server:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    knife data bag from file elasticsearch users.json\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAfter you have configured the node and uploaded all the information to the _Chef_ server,\nrun `chef-client` on the node(s):\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    knife ssh name:elasticsearch* 'sudo chef-client'\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPlease note that all data bags _must_ have attributes enclosed in an environment\n(use the `_default` environment), as suggested by the Chef\n[documentation](http://docs.opscode.com/chef/essentials_data_bags.html#use-data-bags-with-environments).\n\nTesting with Vagrant\n--------------------\n\nThe cookbook comes with a [`Vagrantfile`](https://github.com/elasticsearch/cookbook-elasticsearch/blob/master/Vagrantfile), which allows you to test-drive the installation and configuration with\n[_Vagrant_](http://vagrantup.com/), a tool for building virtualized infrastructures.\n\nFirst, make sure, you have both _VirtualBox_ and _Vagrant_\n[installed](http://docs.vagrantup.com/v1/docs/getting-started/index.html).\n\nThen, clone this repository into an `elasticsearch` directory on your development machine:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    git clone git://github.com/elasticsearch/cookbook-elasticsearch.git elasticsearch\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSwitch to the cloned repository:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    cd elasticsearch\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nInstall the neccessary gems with [Bundler](http://gembundler.com):\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    gem install bundler\n    bundle install\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAll the required third-party cookbooks will be automatically installed via the\n[_Berkshelf_](http://berkshelf.com) integration. If you want to install them\nlocally (eg. to inspect them), use the `berks` command:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    berks install --path ./tmp/cookbooks\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe `Vagrantfile` supports four Linux distributions:\n\n* Ubuntu Precise 64 bit\n* Ubuntu Lucid 32 bit\n* Ubuntu Lucid 64 bit\n* CentOS 6 32 bit\n\nUse the `vagrant status` command for more information.\n\nWe will use the [_Ubuntu Precise 64_](http://vagrantup.com/v1/docs/boxes.html) box for the purpose of this demo.\nYou may want to test-drive this cookbook on a different distribution; check out the available boxes at <http://vagrantbox.es> or build a custom one with [_veewee_](https://github.com/jedi4ever/veewee/tree/master/templates).\n\nLaunch the virtual machine (it will download the box unless you already have it):\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    time bundle exec vagrant up precise64\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe machine will be started and automatically provisioned with\n[_chef-solo_](http://vagrantup.com/v1/docs/provisioners/chef_solo.html).\n(Note: To use the latest version of Chef, run `CHEF=latest vagrant up precise64`.\nYou may substitute _latest_ with a specific version.)\n\nYou'll see _Chef_ debug messages flying by in your terminal, downloading, installing and configuring _Java_,\n_Nginx_, _Elasticsearch_, and all the other components.\nThe process should take less then 10 minutes on a reasonable machine and internet connection.\n\nAfter the process is done, you may connect to _elasticsearch_ via the _Nginx_ proxy from the outside:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    curl 'http://USERNAME:PASSWORD@33.33.33.10:8080/test_chef_cookbook/_search?pretty&q=*'\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOf course, you should connect to the box with SSH and check things out:\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bash\n    bundle exec vagrant ssh precise64\n\n    ps aux | grep elasticsearch\n    service elasticsearch status --verbose\n    curl http://localhost:9200/_cluster/health?pretty\n    sudo monit status elasticsearch\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe cookbook provides test cases in the `files/default/tests/minitest/` directory,\nwhich are executed as a part of the _Chef_ run in _Vagrant_\n(via the [Minitest Chef Handler](https://github.com/calavera/minitest-chef-handler) support).\nThey check the basic installation mechanics, populate the `test_chef_cookbook` index\nwith some sample data, perform a simple search, etc.\n\n\nRepository\n----------\n\nhttp://github.com/elasticsearch/cookbook-elasticsearch\n\nLicense\n-------\n\nAuthor: Karel Minarik (<karmi@elasticsearch.com>) and [contributors](http://github.com/elasticsearch/cookbook-elasticsearch/graphs/contributors)\n\nLicense: Apache\n",
  "requires": [
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/ark",
      "revision": ">= 0.0.0",
      "self_resolve": true
    }
  ],
  "recommends": [
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/build-essential",
      "revision": ">= 0.0.0"
    },
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/xml",
      "revision": ">= 0.0.0"
    },
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/java",
      "revision": ">= 0.0.0"
    },
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/monit",
      "revision": ">= 0.0.0"
    }
  ]
}