{
  "name": "kafka Chef cookbook",
  "chef_cookbook_name": "kafka",
  "revision": "1.0.17",
  "uris": [
    "https://supermarket.chef.io/cookbooks/kafka",
    "https://supermarket.chef.io/cookbooks/kafka/download",
    "https://supermarket.chef.io/cookbooks/kafka/versions/1.0.17",
    "https://supermarket.chef.io/cookbooks/kafka/versions/1.0.17/download",
    "https://supermarket.chef.io/api/v1/cookbooks/kafka/versions/1.0.17",
    "https://supermarket.chef.io/api/v1/cookbooks/kafka",
    "https://supermarket.chef.io/api/v1/cookbooks/kafka/versions/1.0.17/download"
  ],
  "labels": [
    "Chef cookbook",
    "Other",
    "Executable/Script/Chef Cookbook",
    "Mode/Executable/Script/Chef Cookbook"
  ],
  "info_url": "https://supermarket.chef.io/cookbooks/kafka",
  "package_url": "https://supermarket.chef.io/api/v1/cookbooks/kafka/versions/1.0.17/download",
  "deprecated": false,
  "created": "2012-08-21T00:29:02.000Z",
  "updated": "2016-09-22T10:13:01.986Z",
  "description": "Installs and configures a Kafka broker",
  "maintainer": {
    "name": "mthssdrbrg",
    "email": "ivan.vonnagy@webtrends.com"
  },
  "license": "Apache 2.0",
  "chef_foodcritic_failure": false,
  "chef_up_for_adoption": null,
  "rating": null,
  "followers_count": 19,
  "downloads_count": 4989582,
  "downloads_count_revision": 1287980,
  "repository_url": "https://github.com/mthssdrbrg/kafka-cookbook",
  "issues_url": "https://github.com/mthssdrbrg/kafka-cookbook/issues",
  "chef_source_url": "https://github.com/mthssdrbrg/kafka-cookbook",
  "gatherbase_origin": "chef-supermarket",
  "readme": "= DESCRIPTION:\nInstalls kafka 0.7.1\n\n= REQUIREMENTS:\n* Java cookbook version >= 1.5\n* Runit cookbook\n* Zookeeper cookbook - The Kafka cookbook will utilize the clientPort from the Zookeeper cookbook\n  as well as look for a role called \"zookeeper\" that is applied to nodes. All nodes with the role applied\n  to them will be used as the Zookeeper quorum that Kafka connects to.\n\n= ATTRIBUTES:\n\n* kafa.version - The Kafka version to pull and use\n* kafa.install_dir - Location for Kafka to be installed\n* kafa.data_dir - Location for Kafka logs\n* kafa.log_dir - Location for Kafka log4j logs\n* kafa.broker_id - The id of the broker. This must be set to a unique integer for each broker. If not set, it defaults to the machine's ip address without the '.'.\n* kafa.broker_host_name - Hostname the broker will advertise to consumers. If not set, kafka will use the host name for the server being deployed to..\n* kafa.port - The port the socket server listens on\n* kafa.threads - The number of processor threads the socket server uses for receiving and answering requests. If not set, defaults to the number of cores on the machine\n* kafa.log_flush_interval - The number of messages to accept before forcing a flush of data to disk\n* kafa.log_flush_time_interval - The maximum amount of time (ms) a message can sit in a log before we force a flush\n* kafa.log_flush_scheduler_time_interval - The interval (in ms) at which logs are checked to see if they need to be flushed to disk\n* kafa.log_retention_hours - The minimum age of a log file to be eligible for deletion\n\n= USAGE:\n\n* kafka - Install a Kafka broker.\n\n= LICENSE and AUTHOR:\n\nAuthor:: Ivan von Nagy ()\n\nCopyright:: 2012, Webtrends, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.",
  "requires": [
    {
      "kind": "host",
      "label": "debian",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "host",
      "label": "ubuntu",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "host",
      "label": "centos",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "host",
      "label": "redhat",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "host",
      "label": "fedora",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "host",
      "label": "scientific",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "host",
      "label": "amazon",
      "revision": ">= 0.0.0",
      "one_of_group": "os"
    },
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/java",
      "revision": ">= 0.0.0",
      "self_resolve": true
    },
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/runit",
      "revision": ">= 0.0.0",
      "self_resolve": true
    },
    {
      "kind": "env",
      "uri": "https://supermarket.chef.io/cookbooks/zookeeper",
      "revision": ">= 0.0.0",
      "self_resolve": true
    }
  ],
  "chef_recipes": {
    "kafka::default": "Base configuration for kafka"
  },
  "parameters": {
    "kafka/version": {
      "display_name": "Kafka Version",
      "description": "The Kafka version to pull and use",
      "default": "0.7.1",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/home_dir": {
      "display_name": "Kafka Home Directory",
      "description": "Location for Kafka to be located.",
      "default": "/usr/share/kafka",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/data_dir": {
      "display_name": "Kafka Log Directory",
      "description": "Location for Kafka logs.",
      "default": "/usr/share/kafka/kafka-logs",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/log_dir": {
      "display_name": "Kafka log4j Directory",
      "description": ";.",
      "default": "/var/log/kafka",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/broker_id": {
      "display_name": "Kafka Broker Id",
      "description": "The id of the broker. This must be set to a unique integer for each broker. If not set, it defaults to the machine's ip address without the '.'.",
      "default": "",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/broker_host_name": {
      "display_name": "Kafka Host Name",
      "description": "Hostname the broker will advertise to consumers. If not set, kafka will use the host name for the server being deployed to.",
      "default": "",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/port": {
      "display_name": "Kafka Port",
      "description": "The port the socket server listens on.",
      "default": "9092",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/threads": {
      "display_name": "Kafka Threads",
      "description": "The number of processor threads the socket server uses for receiving and answering requests. If not set, defaults to the number of cores on the machine.",
      "default": "",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/log_flush_interval": {
      "display_name": "Kafka Flush Interval",
      "description": "The number of messages to accept before forcing a flush of data to disk.",
      "default": "10000",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/log_flush_time_interval": {
      "display_name": "Kafka Flush Time Interval",
      "description": "The maximum amount of time (ms) a message can sit in a log before we force a flush.",
      "default": "1000",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/log_flush_scheduler_time_interval": {
      "display_name": "Kafka Flush Scheduler Time Interval",
      "description": "The interval (in ms) at which logs are checked to see if they need to be flushed to disk.",
      "default": "1000",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    },
    "kafka/log_retention_hours": {
      "display_name": "Kafka Log Retention Hours",
      "description": "The minimum age of a log file to be eligible for deletion",
      "default": "168",
      "choice": [],
      "calculated": false,
      "type": "string",
      "required": "optional",
      "recipes": [],
      "mapping": "cookbook_attribute"
    }
  }
}