{
  "dockerhub": {
    "web_url": "https://hub.docker.com/r/bryanhong/elasticsearch",
    "repository_url": "https://hub.docker.com/v2/repositories/bryanhong/elasticsearch",
    "tags_url": "https://hub.docker.com/v2/repositories/bryanhong/elasticsearch/tags",
    "dockerfile_url": "https://hub.docker.com/v2/repositories/bryanhong/elasticsearch/dockerfile",
    "autobuild_url": "https://hub.docker.com/v2/repositories/bryanhong/elasticsearch/autobuild",
    "user": "bryanhong",
    "name": "elasticsearch",
    "namespace": "bryanhong",
    "status": 1,
    "is_private": false,
    "is_automated": true,
    "star_count": 0,
    "pull_count": 301,
    "last_updated": "2016-10-13T21:33:06.613325Z",
    "permissions": {
      "read": true,
      "write": false,
      "admin": false
    },
    "tags": [
      {
        "name": "latest",
        "full_size": 253231301,
        "id": 2003475,
        "repository": 528353,
        "creator": 110885,
        "last_updater": 110885,
        "last_updated": "2016-10-13T21:33:05.935747Z",
        "image_id": null,
        "v2": true,
        "platforms": [
          5
        ]
      }
    ],
    "build_name": "bryanhong/docker-elasticsearch"
  },
  "name": "bryanhong/elasticsearch Docker container",
  "description": "Elasticsearch, standalone or clustered",
  "readme": "docker-elasticsearch\n==\n\nElasticsearch in a container\n\n>Elasticsearch is a highly scalable open-source full-text search and analytics engine. It allows you to store, search, and analyze big volumes of data quickly and in near real time. It is generally used as the underlying engine/technology that powers applications that have complex search features and requirements. [elastic.co](https://www.elastic.co/products/elasticsearch)\n\nQuickstart\n--\n\nThe following command will run elasticsearch, if you want to customize or build the container locally, skip to [Building the Container](#building-the-container) below\n\n```\ndocker run                                                         \\\n  --detach=true                                                    \\\n  --log-driver=syslog                                              \\\n  --name=\"elasticsearch\"                                           \\\n  --restart=always                                                 \\\n  --publish 9200:9200                                              \\\n  --volume /dockerhost/dir/for/data:/var/lib/elasticsearch         \\\n  --env CLUSTER_NAME=mycluster                                     \\\n  --env CLUSTER_NODES=\"[\"node2.example.com\", \"node3.example.com\"]\" \\\n  --env DOCKER_HOST_IP=ip.of.docker.host                           \\\n  --env NODE_NAME=node1                                            \\\n  --publish 9300:9300                                              \\\n  bryanhong/elasticsearch:latest\n```\n\n### Runtime flags explained\n\n```\n--detach=true\n```  \nrun the container in the background  \n```\n--log-driver=syslog\n```  \nsend logs to syslog on the Docker host  (requires Docker 1.6 or higher)  \n```\n--name=\"elasticsearch\"\n```  \nname of the container  \n```\n--restart=always\n```  \nautomatically start the container when the Docker daemon starts  \n```\n--publish 9200:9200\n```  \nDocker host port : mapped port in the container (Elasticsearch API)  \n```\n--volume /dockerhost/dir/for/data:/var/lib/elasticsearch\n```  \npath that elasticsearch will use to store its data on the Docker host : mapped path in the container\n\n> The next few flags are for configuring an Elasticsearch cluster, they are optional, if you are setting up a single instance of Elasticsearch you can omit them entirely\n\n```\n--env CLUSTER_NAME=mycluster\n```\nname for your cluster, this should be set the same on other nodes\n```\n--env CLUSTER_NODES=\"[\"node2.example.com\", \"node3.example.com\"]\"\n```\nFQDN or IP addresses of the other members of the cluster, preserve the quoting in the example, it is important\n```\n--env DOCKER_HOST_IP=ip.of.docker.host\n```\nIP address that other cluster members can reach the Docker host on, specifically port 9300 for cluster communications\n```\n--env NODE_NAME=node1\n```\nshort name for this Elasticsearch instance\n```\n--publish 9300:9300\n```\nDocker host port : mapped port in the container (Elasticsearch Transport, cluster members communicate over this port) \n\nGetting Status\n--\nOnce your Elasticsearch container is up and running you should be able to point a web browser or run curl against port 9200 of your Docker host and get a response like this: \n\n```\n$ curl http://node1.example.com:9200\n\n{\n  \"name\" : \"node1\",\n  \"cluster_name\" : \"mycluster\",\n  \"version\" : {\n    \"number\" : \"2.2.0\",\n    \"build_hash\" : \"8ff36d139e16f8720f2947ef62c8167a888992fe\",\n    \"build_timestamp\" : \"2016-01-27T13:32:39Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"5.4.1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n```\nIf you didn't build a cluster then you're on your own from here, checkout the Elasticsearch docs [here](https://www.elastic.co/guide/index.html).\n\nIf you built a cluster you can check health like this:\n\n```\n$ curl http://node1.example.com:9200/_cluster/health?pretty\n\n{\n  \"cluster_name\" : \"mycluster\",\n  \"status\" : \"green\",\n  \"timed_out\" : false,\n  \"number_of_nodes\" : 3,\n  \"number_of_data_nodes\" : 3,\n  \"active_primary_shards\" : 5,\n  \"active_shards\" : 10,\n  \"relocating_shards\" : 0,\n  \"initializing_shards\" : 0,\n  \"unassigned_shards\" : 0,\n  \"delayed_unassigned_shards\" : 0,\n  \"number_of_pending_tasks\" : 0,\n  \"number_of_in_flight_fetch\" : 0,\n  \"task_max_waiting_in_queue_millis\" : 0,\n  \"active_shards_percent_as_number\" : 100.0\n}\n```\nYou're on your own from here, checkout the Elasticsearch docs [here](https://www.elastic.co/guide/index.html).\n\nBuilding the container\n--\n\nIf you want to make modifications to the image or simply see how things work, check out this repository:\n\n```\ngit clone https://github.com/bryanhong/docker-elasticsearch.git\n```\n\n### Commands and variables\n\n* ```vars```: Variables for Docker registry and the application\n* ```build.sh```: Build the Docker image locally\n* ```run.sh```: Starts the Docker container, if the image hasn't been built locally, it is fetched from the repository set in vars\n* ```push.sh```: Pushes the latest locally built image to the repository set in vars\n* ```shell.sh```: get a shell within the container\n\n### How this image/container works\n\n**Data**  \nAll of Elasticsearch's data is bind mounted outside the container to preserve it if the container is removed or rebuilt. Set the location for the bind mount in vars before starting the container.\n\n**Networking**  \nBy default (in vars), Docker will map port 9200 on the Docker host to port 9200 within the container where Elasticsearch listens by default. You can change the external listening port in vars to map to any port you like.\n\n**Security**  \n* **API (port 9200)**  \nElasticsearch does not support authentication or authorization nor does it support the concept of a user. The data in Elasticsearch is readable/writable to anyone that has access to your Dockerhost. It'll be up to you to devise a way to grant/prevent access to the API.\n* **Transport (port 9300)**  \nSimilarly to Elasticsearch's API, there is no authentication or authorization support for transport. Nodes will join a cluster if the CLUSTER_NAME matches and it can reach another Elasticsearch instance set in CLUSTER_NODES.\n\n### Usage\n\n#### Configure the container\n\n1. Configure application specific variables in ```vars```\n\n#### Build the image\n\n1. Run ```./build.sh```\n\n#### Start the container\n\n1. Run ```./run.sh```\n \n#### Pushing your image to the registry\n\nIf you're happy with your container and ready to share with others, push your image up to a [Docker registry](https://docs.docker.com/docker-hub/) and save any other changes you've made so the image can be easily changed or rebuilt in the future.\n\n1. Authenticate to the Docker Registry ```docker login```\n2. Run ```./push.sh```\n3. Log into your Docker hub account and add a description, etc.\n\n> NOTE: If your image will be used FROM other containers you might want to use ```./push.sh flatten``` to consolidate the AUFS layers into a single layer. Keep in mind, you may lose Dockerfile attributes when your image is flattened.\n",
  "dockerfile": "# Copyright 2016 Bryan J. Hong\n# \n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n# \n#     http://www.apache.org/licenses/LICENSE-2.0\n# \n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nFROM ubuntu:14.04\n\nMAINTAINER bryan@turbojets.net\n\nENV DEBIAN_FRONTEND noninteractive\n\n# Add Elastic repository\nRUN echo \"deb http://packages.elastic.co/elasticsearch/2.x/debian stable main\" \\\n > /etc/apt/sources.list.d/elastic.list \\\n && apt-key adv --keyserver pgp.mit.edu --recv-keys D88E42B4\n\n# Update APT repository and install Supervisor\nRUN apt-get -q update \\\n && apt-get -y install supervisor default-jre elasticsearch\n\n# Install Supervisor config\nCOPY assets/supervisord.elasticsearch.conf /etc/supervisor/conf.d/\n\n# Install Startup script\nCOPY assets/startup.sh /opt/startup.sh\n\n# Execute Startup script when container starts\nENTRYPOINT [ \"/opt/startup.sh\" ]\n",
  "dockerfile_json": {
    "add": [],
    "expose": [],
    "volume": [],
    "run": [
      "echo \"deb http://packages.elastic.co/elasticsearch/2.x/debian stable main\"  > /etc/apt/sources.list.d/elastic.list  && apt-key adv --keyserver pgp.mit.edu --recv-keys D88E42B4",
      "apt-get -q update  && apt-get -y install supervisor default-jre elasticsearch"
    ],
    "workdir": [],
    "from": "ubuntu:14.04",
    "maintainer": "bryan@turbojets.net",
    "env": {
      "DEBIAN_FRONTEND": "noninteractive"
    },
    "copy": "assets/startup.sh /opt/startup.sh",
    "entrypoint": "[ \"/opt/startup.sh\" ]"
  },
  "source_repository_url": "https://github.com/bryanhong/docker-elasticsearch.git",
  "source_repository_type": "git",
  "source_repository_provider": "github",
  "source_repository_web_url": "https://github.com/bryanhong/docker-elasticsearch",
  "docker_repository": "bryanhong/elasticsearch",
  "docker_image": "bryanhong/elasticsearch",
  "parameters_schema": {
    "DEBIAN_FRONTEND": {
      "default": "noninteractive",
      "type": "string",
      "mapping": "environment_variable"
    },
    "exposed_ports": {
      "default": [],
      "type": "json_array"
    }
  },
  "type": "docker",
  "docker_name": "bryanhong/elasticsearch",
  "revision": "latest",
  "uris": [
    "https://hub.docker.com/r/bryanhong/elasticsearch",
    "https://hub.docker.com/v2/repositories/bryanhong/elasticsearch",
    "https://github.com/bryanhong/docker-elasticsearch.git"
  ],
  "labels": [
    "Docker",
    "Binding/Region/North America/US",
    "Type/Devopsware/Orchestration/Cluster-based",
    "Type/Middleware/Search/Elasticsearch"
  ],
  "info_url": "https://hub.docker.com/r/bryanhong/elasticsearch",
  "requires": [
    {
      "kind": "host",
      "label": "Docker Engine"
    }
  ],
  "latest": true,
  "gatherbase_origin": "docker-hub"
}