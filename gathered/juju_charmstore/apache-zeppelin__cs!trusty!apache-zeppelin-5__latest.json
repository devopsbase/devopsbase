{
  "name": "apache-zeppelin Juju charm",
  "juju_charm_name": "apache-zeppelin",
  "revision": "cs:trusty/apache-zeppelin-5",
  "latest": true,
  "uris": [
    "https://jujucharms.com/apache-zeppelin",
    "https://jujucharms.com/apache-zeppelin/trusty",
    "https://jujucharms.com/apache-zeppelin/trusty/5",
    "https://api.jujucharms.com/v5/apache-zeppelin",
    "https://api.jujucharms.com/v5/trusty/apache-zeppelin",
    "https://api.jujucharms.com/v5/trusty/apache-zeppelin-5"
  ],
  "labels": [
    "Juju charm",
    "bigdata",
    "hadoop",
    "apache",
    "Type/Middleware/Runtime/Java",
    "Mode/Guide/Text/Book",
    "Mode/Executable/Bundle/Juju Charm",
    "Type/Devopsware/IDE/Web-based",
    "Type/Devopsware/Deployment/Juju",
    "Type/Middleware/Web Server/Apache HTTP Server",
    "Type/Middleware/Data Processing"
  ],
  "info_url": "https://jujucharms.com/apache-zeppelin",
  "package_url": "https://api.jujucharms.com/v5/trusty/apache-zeppelin-5/archive",
  "created": "2015-10-07T21:16:55.071Z",
  "updated": "2015-10-07T21:16:55.071Z",
  "description": "A web-based notebook that enables interactive data analytics.\n\nApache Zeppelin is a web-based notebook that enables interactive data\nanalytics. You can make beautiful data-driven, interactive, and collaborative\ndocuments with SQL, Scala and more.\n",
  "maintainer": {
    "name": "bigdata-charmers"
  },
  "juju_charm_subordinate": true,
  "juju_charm_series": "trusty",
  "juju_charm_owner": "bigdata-charmers",
  "requires": [
    {
      "kind": "host",
      "label": "Infrastructure/Operating System/Linux/Ubuntu",
      "version": "= trusty"
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/spark",
      "self_resolve": true,
      "juju_interface": "spark",
      "juju_name": "spark",
      "juju_role": "requirer",
      "juju_limit": 1
    }
  ],
  "parameters": {
    "resources_mirror": {
      "type": "string",
      "description": "URL from which to fetch resources (e.g., Hadoop binaries) instead of Launchpad.\n",
      "default": "",
      "mapping": "charm_option"
    }
  },
  "license": "## Overview\n\nApache Zeppelin is a web-based notebook that enables interactive data analytics.\nYou can make beautiful data-driven, interactive, and collaborative documents\nwith SQL, Scala and more.\n\nAs a Multi-purpose Notebook, Apache Zeppelin is the place for interactive:\n\n * Data Ingestion\n * Data Discovery\n * Data Analytics\n * Data Visualization & Collaboration\n\n\n## Usage\n\nThis is a subordinate charm that requires the `apache-spark` interface. This\nmeans that you will need to deploy a base Apache Spark cluster to use\nZeppelin. An easy way to deploy the recommended environment is to use the\n[apache-hadoop-spark-zeppelin](https://jujucharms.com/apache-hadoop-spark-zeppelin)\nbundle. This will deploy the Apache Hadoop platform with an Apache Spark +\nZeppelin unit that communicates with the cluster by relating to the\n`apache-hadoop-plugin` subordinate charm:\n\n    juju-quickstart apache-hadoop-spark-zeppelin\n\nAlternatively, you may manually deploy the recommended environment as follows:\n\n    juju deploy apache-hadoop-hdfs-master hdfs-master\n    juju deploy apache-hadoop-yarn-master yarn-master\n    juju deploy apache-hadoop-compute-slave compute-slave\n    juju deploy apache-hadoop-plugin plugin\n    juju deploy apache-spark spark\n    juju deploy apache-zeppelin zeppelin\n\n    juju add-relation yarn-master hdfs-master\n    juju add-relation compute-slave yarn-master\n    juju add-relation compute-slave hdfs-master\n    juju add-relation plugin yarn-master\n    juju add-relation plugin hdfs-master\n    juju add-relation spark plugin\n    juju add-relation zeppelin spark\n\nOnce deployment is complete, expose the zeppelin service:\n\n    juju expose zeppelin\n\nYou may now access the web interface at\nhttp://{spark_unit_ip_address}:9090. The ip address can be found by running\n`juju status spark | grep public-address`.\n\n\n## Testing the deployment\n\nBy default, this deployment uses Spark in YARN mode and supports storing\njob data in HDFS. To test this, access the Zeppelin web interface at\nhttp://{spark_unit_ip_address}:9090. The ip address can be found by running\n`juju status spark | grep public-address`.\n\n  - Verify there is a green icon in the upper-right corner that says \"Connected\"\n  - Click the `Zeppelin HDFS Tutorial` link\n  - Click the `Save` button to bind the tutorial to our supported interpreters\n  - Click the `Play` button (arrow at the top of the page)\n  - Click `OK` when prompted to run all paragraphs\n\nThe tutorial may take 5-10 minutes to run as it retrieves sample data,\nprocesses jobs, and stores results in HDFS. When successful, each paragraph will\nreport `FINISHED` in their respective upper-right corners\n\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n",
  "readme": "## Overview\n\nApache Zeppelin is a web-based notebook that enables interactive data analytics.\nYou can make beautiful data-driven, interactive, and collaborative documents\nwith SQL, Scala and more.\n\nAs a Multi-purpose Notebook, Apache Zeppelin is the place for interactive:\n\n * Data Ingestion\n * Data Discovery\n * Data Analytics\n * Data Visualization & Collaboration\n\n\n## Usage\n\nThis is a subordinate charm that requires the `apache-spark` interface. This\nmeans that you will need to deploy a base Apache Spark cluster to use\nZeppelin. An easy way to deploy the recommended environment is to use the\n[apache-hadoop-spark-zeppelin](https://jujucharms.com/apache-hadoop-spark-zeppelin)\nbundle. This will deploy the Apache Hadoop platform with an Apache Spark +\nZeppelin unit that communicates with the cluster by relating to the\n`apache-hadoop-plugin` subordinate charm:\n\n    juju-quickstart apache-hadoop-spark-zeppelin\n\nAlternatively, you may manually deploy the recommended environment as follows:\n\n    juju deploy apache-hadoop-hdfs-master hdfs-master\n    juju deploy apache-hadoop-yarn-master yarn-master\n    juju deploy apache-hadoop-compute-slave compute-slave\n    juju deploy apache-hadoop-plugin plugin\n    juju deploy apache-spark spark\n    juju deploy apache-zeppelin zeppelin\n\n    juju add-relation yarn-master hdfs-master\n    juju add-relation compute-slave yarn-master\n    juju add-relation compute-slave hdfs-master\n    juju add-relation plugin yarn-master\n    juju add-relation plugin hdfs-master\n    juju add-relation spark plugin\n    juju add-relation zeppelin spark\n\nOnce deployment is complete, expose the zeppelin service:\n\n    juju expose zeppelin\n\nYou may now access the web interface at\nhttp://{spark_unit_ip_address}:9090. The ip address can be found by running\n`juju status spark | grep public-address`.\n\n\n## Testing the deployment\n\nBy default, this deployment uses Spark in YARN mode and supports storing\njob data in HDFS. To test this, access the Zeppelin web interface at\nhttp://{spark_unit_ip_address}:9090. The ip address can be found by running\n`juju status spark | grep public-address`.\n\n  - Verify there is a green icon in the upper-right corner that says \"Connected\"\n  - Click the `Zeppelin HDFS Tutorial` link\n  - Click the `Save` button to bind the tutorial to our supported interpreters\n  - Click the `Play` button (arrow at the top of the page)\n  - Click `OK` when prompted to run all paragraphs\n\nThe tutorial may take 5-10 minutes to run as it retrieves sample data,\nprocesses jobs, and stores results in HDFS. When successful, each paragraph will\nreport `FINISHED` in their respective upper-right corners\n\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n",
  "readme_name": "README.md",
  "gatherbase_origin": "juju-charmstore"
}