{
  "name": "hdp-tez Juju charm",
  "juju_charm_name": "hdp-tez",
  "revision": "cs:trusty/hdp-tez-5",
  "latest": true,
  "uris": [
    "https://jujucharms.com/hdp-tez",
    "https://jujucharms.com/hdp-tez/trusty",
    "https://jujucharms.com/hdp-tez/trusty/5",
    "https://api.jujucharms.com/v5/hdp-tez",
    "https://api.jujucharms.com/v5/trusty/hdp-tez",
    "https://api.jujucharms.com/v5/trusty/hdp-tez-5"
  ],
  "labels": [
    "Juju charm",
    "Applications",
    "Binding/Provider/HP",
    "Mode/Executable/Bundle/Juju Charm",
    "Mode/API/Toolkit",
    "Style/Virtualization Level/Application",
    "Type/Devopsware/Build",
    "Type/Devopsware/Deployment/Juju",
    "Type/Infrastructure/Operating System",
    "Type/Middleware/Web Server/Apache HTTP Server",
    "Type/Middleware/Data Processing/Hadoop/Hive"
  ],
  "info_url": "https://jujucharms.com/hdp-tez",
  "package_url": "https://api.jujucharms.com/v5/trusty/hdp-tez-5/archive",
  "created": "2015-06-17T09:30:51.314Z",
  "updated": "2015-06-17T09:30:51.314Z",
  "description": "With Tez, Hadoop provides both interactive and batch queries.\n\nApache™ Tez is an extensible framework for building YARN based, high performance batch and interactive data processing applications in Hadoop that need to handle TB to PB scale datasets. It allows projects in the Hadoop ecosystem, such as Apache Hive and Apache Pig, as well as 3rd-party software vendors to express fit-to-purpose data processing applications in a way that meets their unique demands for fast response times and extreme throughput at petabyte scale.\n",
  "maintainer": {
    "name": "bigdata-charmers"
  },
  "juju_charm_subordinate": false,
  "juju_charm_series": "trusty",
  "juju_charm_owner": "bigdata-charmers",
  "requires": [
    {
      "kind": "host",
      "label": "Infrastructure/Operating System/Linux/Ubuntu",
      "version": "= trusty"
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/mapred",
      "self_resolve": true,
      "juju_interface": "mapred",
      "juju_name": "hadoop-nodes",
      "juju_role": "requirer",
      "juju_limit": 1
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/dfs",
      "self_resolve": true,
      "juju_interface": "dfs",
      "juju_name": "namenode",
      "juju_role": "requirer",
      "juju_limit": 1
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/mapred",
      "self_resolve": true,
      "juju_interface": "mapred",
      "juju_name": "resourcemanager",
      "juju_role": "requirer",
      "juju_limit": 1
    }
  ],
  "license": "# **What is Tez**\nApache Tez, a Framework for YARN-based, Data Processing Applications In Hadoop.\n\nApache™ Tez is an extensible framework for building YARN based, high performance\nbatch and interactive data processing applications in Hadoop that need to handle\nTB to PB scale datasets. It allows projects in the Hadoop ecosystem, such as\nApache Hive and Apache Pig, as well as 3rd-party software vendors to express\nfit-to-purpose data processing applications in a way that meets their unique\ndemands for fast response times and extreme throughput at petabyte scale.\n\nWhy Apache Tez\nApache Tez  provides a developer API and framework to write native YARN\napplications that bridge the spectrum of interactive and batch workloads.\nIt allows applications to seamlessly span the scalability dimension from\nGB’s to PB’s of data and 10’s to 1000’s of nodes. The Apache Tez component\nlibrary allows developers to use Tez to create Hadoop applications that\n integrate with YARN and perform well within mixed workload Hadoop clusters.\n\nAnd, since Tez is extensible and embeddable, it provides the fit-to-purpose\n freedom to express highly optimized data processing applications, giving\nthem an advantage over general-purpose, end-user-facing engines such as\nMapReduce and Spark. Finally, it offers a customizable execution architecture\nthat allows you to express complex computations as dataflow graphs and allows\nfor dynamic performance optimizations based on real information about the data\n and the resources required to process it.\n\n## **Tez usecase**\n\nVerify that your cluster meets the following pre-requisites before installing Tez:\nApache Hadoop 2.4.x & YARN\n\n**To deploy a four node Hadoop cluster**\n\n\n    juju deploy hdp-hadoop yarn-hdfs-master\n    juju deploy hdp-hadoop compute-node\n    juju add-unit -n 2 compute-node\n    juju add-relation yarn-hdfs-master:namenode compute-node:datanode\n    juju add-relation yarn-hdfs-master:resourcemanager compute-node:nodemanager\n\n\n**To deploy a Tez Client::**\n\n    juju deploy hdp-tez hdp-tez\n    juju add-relation hdp-tez:resourcemanager yarn-hdfs-master:resourcemanager\n    juju add-relation hdp-tez:namenode yarn-hdfs-master:namenode\n    juju add-relation hdp-tez:hadoop-nodes compute-node:hadoop-nodes\n\n\n## **TEZ scale**\n\n    juju add-unit -n 2 compute-node\n\n## **Verify deployment**\n execute:  \n\n    $juju run \"sudo su hdfs -c 'hdfs dfs -ls /apps/tez'\" --unit hdp-tez/0\n\n A successful result:\n\n     hdfs users   ...  /apps/tez/conf\n     hdfs users   ...  /apps/tez/lib\n     hdfs users   ...  /apps/tez/tez-api-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-common-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-dag-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-mapreduce-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-mapreduce-examples-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-runtime-internals-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-runtime-library-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-tests-0.4.0.2.1.3.0-563.jar\n\n **HDFS validation from Tez Client**\n 1) Remote HDFS Cluster health\n\n     $juju run \"su hdfs -c 'hdfs dfsadmin -report '\" --unit hdp-tez/0\n    ** validate the returned information **\n 2) Validate a successful create directory on hdfs cluster\n\n    $juju run \"su hdfs -c 'hdfs dfs -mkdir /tmp'\" --unit hdp-tez/0\n\n 3) Copy a test data file to hdfs cluster\n\n    $juju run \"su hdfs -c 'hdfs dfs -put /home/ubuntu/pg4300.txt /tmp '\" --unit hdp-tez/0\n\n 4) Run Tez world-count example -  \n\n    $ juju run \"/home/ubuntu/runtez_wc.sh\" --unit hdp-tez/0\n\n 5) View the result save on hdfs cluster:\n\n    $juju run \"su hdfs -c 'hdfs dfs -cat /tmp/pg4300.out/* '\" --unit hdp-tez/0\n\n\n## **Tez Contact Information**\nAmir Sanjar <amir.sanjar@canonical.com>\n\n## **Hortonworks Tez**\n\n- [Hortonworks website](http://hortonworks.com/)\n",
  "readme": "# **What is Tez**\nApache Tez, a Framework for YARN-based, Data Processing Applications In Hadoop.\n\nApache™ Tez is an extensible framework for building YARN based, high performance\nbatch and interactive data processing applications in Hadoop that need to handle\nTB to PB scale datasets. It allows projects in the Hadoop ecosystem, such as\nApache Hive and Apache Pig, as well as 3rd-party software vendors to express\nfit-to-purpose data processing applications in a way that meets their unique\ndemands for fast response times and extreme throughput at petabyte scale.\n\nWhy Apache Tez\nApache Tez  provides a developer API and framework to write native YARN\napplications that bridge the spectrum of interactive and batch workloads.\nIt allows applications to seamlessly span the scalability dimension from\nGB’s to PB’s of data and 10’s to 1000’s of nodes. The Apache Tez component\nlibrary allows developers to use Tez to create Hadoop applications that\n integrate with YARN and perform well within mixed workload Hadoop clusters.\n\nAnd, since Tez is extensible and embeddable, it provides the fit-to-purpose\n freedom to express highly optimized data processing applications, giving\nthem an advantage over general-purpose, end-user-facing engines such as\nMapReduce and Spark. Finally, it offers a customizable execution architecture\nthat allows you to express complex computations as dataflow graphs and allows\nfor dynamic performance optimizations based on real information about the data\n and the resources required to process it.\n\n## **Tez usecase**\n\nVerify that your cluster meets the following pre-requisites before installing Tez:\nApache Hadoop 2.4.x & YARN\n\n**To deploy a four node Hadoop cluster**\n\n\n    juju deploy hdp-hadoop yarn-hdfs-master\n    juju deploy hdp-hadoop compute-node\n    juju add-unit -n 2 compute-node\n    juju add-relation yarn-hdfs-master:namenode compute-node:datanode\n    juju add-relation yarn-hdfs-master:resourcemanager compute-node:nodemanager\n\n\n**To deploy a Tez Client::**\n\n    juju deploy hdp-tez hdp-tez\n    juju add-relation hdp-tez:resourcemanager yarn-hdfs-master:resourcemanager\n    juju add-relation hdp-tez:namenode yarn-hdfs-master:namenode\n    juju add-relation hdp-tez:hadoop-nodes compute-node:hadoop-nodes\n\n\n## **TEZ scale**\n\n    juju add-unit -n 2 compute-node\n\n## **Verify deployment**\n execute:  \n\n    $juju run \"sudo su hdfs -c 'hdfs dfs -ls /apps/tez'\" --unit hdp-tez/0\n\n A successful result:\n\n     hdfs users   ...  /apps/tez/conf\n     hdfs users   ...  /apps/tez/lib\n     hdfs users   ...  /apps/tez/tez-api-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-common-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-dag-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-mapreduce-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-mapreduce-examples-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-runtime-internals-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-runtime-library-0.4.0.2.1.3.0-563.jar\n     hdfs users   ...  /apps/tez/tez-tests-0.4.0.2.1.3.0-563.jar\n\n **HDFS validation from Tez Client**\n 1) Remote HDFS Cluster health\n\n     $juju run \"su hdfs -c 'hdfs dfsadmin -report '\" --unit hdp-tez/0\n    ** validate the returned information **\n 2) Validate a successful create directory on hdfs cluster\n\n    $juju run \"su hdfs -c 'hdfs dfs -mkdir /tmp'\" --unit hdp-tez/0\n\n 3) Copy a test data file to hdfs cluster\n\n    $juju run \"su hdfs -c 'hdfs dfs -put /home/ubuntu/pg4300.txt /tmp '\" --unit hdp-tez/0\n\n 4) Run Tez world-count example -  \n\n    $ juju run \"/home/ubuntu/runtez_wc.sh\" --unit hdp-tez/0\n\n 5) View the result save on hdfs cluster:\n\n    $juju run \"su hdfs -c 'hdfs dfs -cat /tmp/pg4300.out/* '\" --unit hdp-tez/0\n\n\n## **Tez Contact Information**\nAmir Sanjar <amir.sanjar@canonical.com>\n\n## **Hortonworks Tez**\n\n- [Hortonworks website](http://hortonworks.com/)\n",
  "readme_name": "README.md",
  "gatherbase_origin": "juju-charmstore"
}