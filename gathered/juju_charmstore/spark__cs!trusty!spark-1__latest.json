{
  "name": "spark Juju charm",
  "juju_charm_name": "spark",
  "revision": "cs:trusty/spark-1",
  "latest": true,
  "uris": [
    "https://jujucharms.com/spark",
    "https://jujucharms.com/spark/trusty",
    "https://jujucharms.com/spark/trusty/1",
    "https://api.jujucharms.com/v5/spark",
    "https://api.jujucharms.com/v5/trusty/spark",
    "https://api.jujucharms.com/v5/trusty/spark-1"
  ],
  "labels": [
    "Juju charm",
    "bigdata",
    "apache",
    "hadoop",
    "applications",
    "Mode/Executable/Bundle/Juju Charm",
    "Style/Virtualization Level/Application",
    "Type/Devopsware/Deployment/Juju",
    "Type/Middleware/Web Server/Apache HTTP Server",
    "Type/Middleware/Data Processing/Hadoop"
  ],
  "info_url": "https://jujucharms.com/spark",
  "package_url": "https://api.jujucharms.com/v5/trusty/spark-1/archive",
  "created": "2016-08-23T16:09:54.012Z",
  "updated": "2016-08-23T16:09:54.012Z",
  "description": "Apache Spark from Apache Bigtop platform\n\nHadoop is a software platform that lets one easily write and run applications that process vast amounts of data.\nThis charm provides a Apache Spark via the Apache Bigtop Spark component.\n",
  "maintainer": {
    "name": "bigdata-charmers"
  },
  "juju_charm_subordinate": false,
  "juju_charm_series": "trusty",
  "juju_charm_owner": "bigdata-charmers",
  "requires": [
    {
      "kind": "host",
      "label": "Infrastructure/Operating System/Linux/Ubuntu",
      "version": "= trusty"
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/zookeeper",
      "self_resolve": true,
      "juju_interface": "zookeeper",
      "juju_name": "zookeeper",
      "juju_role": "requirer",
      "juju_limit": 1
    }
  ],
  "parameters": {
    "auto-start": {
      "type": "boolean",
      "description": "Set puppet agent auto-start, defaults to true.\n",
      "default": true,
      "mapping": "charm_option"
    },
    "ca-server": {
      "type": "string",
      "description": "Puppet ca-server fqdn.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "environment": {
      "type": "string",
      "description": "Puppet environment.\n",
      "default": "production",
      "mapping": "charm_option"
    },
    "extra_packages": {
      "type": "string",
      "description": "Space separated list of extra deb packages to install.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "install_keys": {
      "type": "string",
      "description": "List of signing keys for install_sources package sources, per charmhelpers standard format (a yaml list of strings encoded as a string). The keys should be the full ASCII armoured GPG public keys. While GPG key ids are also supported and looked up on a keyserver, operators should be aware that this mechanism is insecure. null can be used if a standard package signing key is used that will already be installed on the machine, and for PPA sources where the package signing key is securely retrieved from Launchpad.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "install_sources": {
      "type": "string",
      "description": "List of extra apt sources, per charm-helpers standard format (a yaml list of strings encoded as a string). Each source may be either a line that can be added directly to sources.list(5), or in the form ppa:<user>/<ppa-name> for adding Personal Package Archives, or a distribution component to enable.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "package_status": {
      "type": "string",
      "description": "The status of service-affecting packages will be set to this value in the dpkg database. Valid values are \"install\" and \"hold\".\n",
      "default": "install",
      "mapping": "charm_option"
    },
    "pin-puppet": {
      "type": "string",
      "description": "This will override the system default for the\ngeneral version of puppet specified by the\npuppet-version layer option.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "puppet-gpg-id": {
      "type": "string",
      "description": "Puppetlabs gpg-key id.\n",
      "default": "4BD6EC30",
      "mapping": "charm_option"
    },
    "puppet-gpg-key": {
      "type": "string",
      "description": "Puppet gpg id used to configure Puppetlabs apt sources\n",
      "default": "-----BEGIN PGP PUBLIC KEY BLOCK-----\nVersion: GnuPG v1.4.12 (GNU/Linux)\nComment: GPGTools - https://gpgtools.org\n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\nMfJRfFYEkpFi1OffGhvIMA==\n=EXlz\n-----END PGP PUBLIC KEY BLOCK-----\n",
      "mapping": "charm_option"
    },
    "puppet-server": {
      "type": "string",
      "description": "Puppetmaster fqdn.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "resources_mirror": {
      "type": "string",
      "description": "URL used to fetch resources (e.g., Hadoop binaries) instead of the\nlocation specified in resources.yaml.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "spark_bench_enabled": {
      "type": "boolean",
      "description": "When set to 'true' (the default), this charm will download and\ninstall the SparkBench benchmark suite from the configured URLs.\nWhen set to 'false', SparkBench will be removed from the unit,\nthough any data stored in hdfs:///user/ubuntu/spark-bench will be\npreserved.\n",
      "default": true,
      "mapping": "charm_option"
    },
    "spark_bench_ppc64le": {
      "type": "string",
      "description": "URL (including hash) of a ppc64le tarball of SparkBench. By\ndefault, this points to a pre-built SparkBench binary based on\nsources in the upstream repository. This option is only valid when\n'spark_bench_enabled' is 'true'.\n",
      "default": "https://s3.amazonaws.com/jujubigdata/ibm/noarch/spark-bench-2.0-20151214-ffb72f23.tgz#sha256=ffb72f233eaafccef4dda6d4516f23e043d1b14b9d63734211f4d1968db86a3c",
      "mapping": "charm_option"
    },
    "spark_bench_x86_64": {
      "type": "string",
      "description": "URL (including hash) of an x86_64 tarball of SparkBench. By\ndefault, this points to a pre-built SparkBench binary based on\nsources in the upstream repository. This option is only valid when\n'spark_bench_enabled' is 'true'.\n",
      "default": "https://s3.amazonaws.com/jujubigdata/ibm/noarch/spark-bench-2.0-20151214-ffb72f23.tgz#sha256=ffb72f233eaafccef4dda6d4516f23e043d1b14b9d63734211f4d1968db86a3c",
      "mapping": "charm_option"
    },
    "spark_execution_mode": {
      "type": "string",
      "description": "Options are \"local\", \"standalone\", \"yarn-client\", and\n\"yarn-cluster\". Consult the readme for details on these options.\n",
      "default": "standalone",
      "mapping": "charm_option"
    }
  },
  "provides": [
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/benchmark",
      "juju_interface": "benchmark",
      "juju_name": "benchmark",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/spark",
      "juju_interface": "spark",
      "juju_name": "client",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/hadoop-plugin",
      "juju_interface": "hadoop-plugin",
      "juju_name": "hadoop",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/java",
      "juju_interface": "java",
      "juju_name": "java",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/mahout",
      "juju_interface": "mahout",
      "juju_name": "mahout",
      "juju_role": "provider",
      "juju_limit": 0
    }
  ],
  "juju_peers": {
    "sparkpeers": {
      "Name": "sparkpeers",
      "Role": "peer",
      "Interface": "spark-quorum",
      "Optional": false,
      "Limit": 1,
      "Scope": "global"
    }
  },
  "license": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n  The ASF licenses this file to You under the Apache License, Version 2.0\n  (the \"License\"); you may not use this file except in compliance with\n  the License.  You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n## Spark Overview\n\n### Spark Cluster\n\nApache Spark™ is a fast and general purpose engine for large-scale data\nprocessing. Key features:\n\n * **Speed**\n\n Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster\n on disk. Spark has an advanced DAG execution engine that supports cyclic data\n flow and in-memory computing.\n\n * **Ease of Use**\n\n Write applications quickly in Java, Scala or Python. Spark offers over 80\n high-level operators that make it easy to build parallel apps, and you can use\n it interactively from the Scala and Python shells.\n\n * **General Purpose Engine**\n\n Combine SQL, streaming, and complex analytics. Spark powers a stack of\n high-level tools including Shark for SQL, MLlib for machine learning, GraphX,\n and Spark Streaming. You can combine these frameworks seamlessly in the same\n application.\n\n\n## Deployment\n\nThis charm allows the deployment of Apache Spark packaged by Apache Bigtop\nin the modes described below:\n\n * **Standalone**\n\n In this mode Spark units form a cluster that you can scale to match your needs.\n Starting with a single node:\n\n    juju deploy spark\n    juju deploy openjdk\n    juju add-relation spark openjdk\n\n You can scale the cluster by adding more spark units:\n\n    juju add-unit spark\n\n When in standalone mode Juju ensures a single Spark master is appointed.\n The status of the unit acting as master reads \"ready (standalone - master)\",\n while the rest of the units display a status of  \"ready (standalone)\".\n In case you remove the master unit Juju will appoint a new master to the cluster.\n However, should a master fail in this standalone mode running jobs and job history\n will be lost.\n\n * **Standalone HA**\n\n To enable High Availability properties of a cluster you need to add a relation\n between spark and a zookeeper deployment. For instance:\n\n    juju deploy apache-zookeeper zookeeper\n    juju add-relation spark zookeeper\n\n In this mode again you can scale your cluster to match your needs by adding/removing\n units. Spark units report \"ready (standalone HA)\" in their status so if you need to\n identify the node acting as master you need to query the Zookeeper deployment.\n\n    juju ssh zk/0\n    zkCli.sh\n    get /spark/master_status\n\n * **Yarn-client and Yarn-cluster**\n\n This charm leverages our pluggable Hadoop model with the `hadoop-plugin`\n interface. This means that you can relate this charm to a base Apache Hadoop cluster\n to run Spark jobs there. The suggested deployment method is to use the\n [hadoop-processing](https://jujucharms.com/hadoop-processing/)\n bundle and add a relation between spark and the plugin:\n\n    juju deploy hadoop-processing\n    juju add-relation plugin spark\n\n\nNote: To transition among execution modes you need to set the\n`spark_execution_mode` config variable:\n\n    juju set spark spark_execution_mode=<new_mode>\n\n## Usage\n\nOnce deployment is complete, you can manually load and run Spark batch or\nstreaming jobs in a variety of ways:\n\n  * **Spark shell**\n\nSpark’s shell provides a simple way to learn the API, as well as a powerful\ntool to analyse data interactively. It is available in either Scala or Python\nand can be run from the Spark unit as follows:\n\n       juju ssh spark/0\n       spark-shell # for interaction using scala\n       pyspark     # for interaction using python\n\n  * **Command line**\n\nSSH to the Spark unit and manually run a spark-submit job, for example:\n\n       juju ssh spark/0\n       spark-submit --class org.apache.spark.examples.SparkPi \\\n        --master yarn-client /usr/lib/spark/lib/spark-examples*.jar 10\n\n  * **Apache Zeppelin visual service**\n\nDeploy Apache Zeppelin and relate it to the Spark unit:\n\n    juju deploy apache-zeppelin zeppelin\n    juju add-relation spark zeppelin\n\nOnce the relation has been made, access the web interface at\n`http://{spark_unit_ip_address}:9090`\n\n  * **IPyNotebook for Spark**\n\nThe IPython Notebook is an interactive computational environment, in which you\ncan combine code execution, rich text, mathematics, plots and rich media.\nDeploy IPython Notebook for Spark and relate it to the Spark unit:\n\n    juju deploy apache-spark-notebook notebook\n    juju add-relation spark notebook\n\nOnce the relation has been made, access the web interface at\n`http://{spark_unit_ip_address}:8880`\n\n\n## Configuration\n\n### `spark_bench_enabled`\n\nInstall the SparkBench benchmarking suite. If `true` (the default), this charm\nwill download spark bench from the URL specified by `spark_bench_ppc64le`\nor `spark_bench_x86_64`, depending on the unit's architecture.\n\n### `spark_execution_mode`\n\nSpark has four modes of execution: local, standalone, yarn-client, and\nyarn-cluster. The default mode is `yarn-client` and can be changed by setting\nthe `spark_execution_mode` config variable.\n\n  * **Local**\n\n    In Local mode, Spark processes jobs locally without any cluster resources.\n    There are 3 ways to specify 'local' mode:\n\n    * `local`\n\n      Run Spark locally with one worker thread (i.e. no parallelism at all).\n\n    * `local[K]`\n\n      Run Spark locally with K worker threads (ideally, set this to the number\n      of cores on your machine).\n\n    * `local[*]`\n\n      Run Spark locally with as many worker threads as logical cores on your\n      machine.\n\n  * **Standalone**\n\n    In `standalone` mode, Spark launches a Master and Worker daemon on the Spark\n    unit. This mode is useful for simulating a distributed cluster environment\n    without actually setting up a cluster.\n\n  * **YARN-client**\n\n    In `yarn-client` mode, the driver runs in the client process, and the\n    application master is only used for requesting resources from YARN.\n\n  * **YARN-cluster**\n\n    In `yarn-cluster` mode, the Spark driver runs inside an application master\n    process which is managed by YARN on the cluster, and the client can go away\n    after initiating the application.\n\n\n## Verify the deployment\n\n### Status and Smoke Test\n\nThe services provide extended status reporting to indicate when they are ready:\n\n    juju status --format=tabular\n\nThis is particularly useful when combined with `watch` to track the on-going\nprogress of the deployment:\n\n    watch -n 0.5 juju status --format=tabular\n\nThe message for each unit will provide information about that unit's state.\nOnce they all indicate that they are ready, you can perform a \"smoke test\"\nto verify that Spark is working as expected using the built-in `smoke-test`\naction:\n\n    juju run-action spark/0 smoke-test\n\n_**Note**: The above assumes Juju 2.0 or greater. If using an earlier version\nof Juju, the syntax is `juju action do spark/0 smoke-test`._\n\n\nAfter a minute or so, you can check the results of the smoke test:\n\n    juju show-action-status\n\n_**Note**: The above assumes Juju 2.0 or greater. If using an earlier version\nof Juju, the syntax is `juju action status`._\n\nYou will see `status: completed` if the smoke test was successful, or\n`status: failed` if it was not.  You can get more information on why it failed\nvia:\n\n    juju show-action-output <action-id>\n\n_**Note**: The above assumes Juju 2.0 or greater. If using an earlier version\nof Juju, the syntax is `juju action fetch <action-id>`._\n\n\n### Verify Job History\n\nThe Job History server shows all active and finished spark jobs submitted.\nTo view the Job History server you need to expose spark (`juju expose spark`)\nand navigate to `http://{spark_master_unit_ip_address}:18080` of the\nunit acting as master.\n\n\n## Benchmarking\n\nThis charm provides several benchmarks, including the\n[Spark Bench](https://github.com/SparkTC/spark-bench) benchmarking\nsuite (if enabled), to gauge the performance of your environment.\n\nThe easiest way to run the benchmarks on this service is to relate it to the\n[Benchmark GUI][].  You will likely also want to relate it to the\n[Benchmark Collector][] to have machine-level information collected during the\nbenchmark, for a more complete picture of how the machine performed.\n\n[Benchmark GUI]: https://jujucharms.com/benchmark-gui/\n[Benchmark Collector]: https://jujucharms.com/benchmark-collector/\n\nHowever, each benchmark is also an action that can be called manually:\n\n    $ juju action do spark/0 pagerank\n    Action queued with id: 88de9367-45a8-4a4b-835b-7660f467a45e\n    $ juju action fetch --wait 0 88de9367-45a8-4a4b-835b-7660f467a45e\n    results:\n      meta:\n        composite:\n          direction: asc\n          units: secs\n          value: \"77.939000\"\n        raw: |\n          PageRank,2015-12-10-23:41:57,77.939000,71.888079,.922363,0,PageRank-MLlibConfig,,,,,10,12,,200000,4.0,1.3,0.15\n        start: 2015-12-10T23:41:34Z\n        stop: 2015-12-10T23:43:16Z\n      results:\n        duration:\n          direction: asc\n          units: secs\n          value: \"77.939000\"\n        throughput:\n          direction: desc\n          units: x/sec\n          value: \".922363\"\n    status: completed\n    timing:\n      completed: 2015-12-10 23:43:59 +0000 UTC\n      enqueued: 2015-12-10 23:42:10 +0000 UTC\n      started: 2015-12-10 23:42:15 +0000 UTC\n\nValid action names at this time are:\n\n  * logisticregression\n  * matrixfactorization\n  * pagerank\n  * sql\n  * streaming\n  * svdplusplus\n  * svm\n  * trianglecount\n  * sparkpi\n\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n",
  "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n  The ASF licenses this file to You under the Apache License, Version 2.0\n  (the \"License\"); you may not use this file except in compliance with\n  the License.  You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n## Spark Overview\n\n### Spark Cluster\n\nApache Spark™ is a fast and general purpose engine for large-scale data\nprocessing. Key features:\n\n * **Speed**\n\n Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster\n on disk. Spark has an advanced DAG execution engine that supports cyclic data\n flow and in-memory computing.\n\n * **Ease of Use**\n\n Write applications quickly in Java, Scala or Python. Spark offers over 80\n high-level operators that make it easy to build parallel apps, and you can use\n it interactively from the Scala and Python shells.\n\n * **General Purpose Engine**\n\n Combine SQL, streaming, and complex analytics. Spark powers a stack of\n high-level tools including Shark for SQL, MLlib for machine learning, GraphX,\n and Spark Streaming. You can combine these frameworks seamlessly in the same\n application.\n\n\n## Deployment\n\nThis charm allows the deployment of Apache Spark packaged by Apache Bigtop\nin the modes described below:\n\n * **Standalone**\n\n In this mode Spark units form a cluster that you can scale to match your needs.\n Starting with a single node:\n\n    juju deploy spark\n    juju deploy openjdk\n    juju add-relation spark openjdk\n\n You can scale the cluster by adding more spark units:\n\n    juju add-unit spark\n\n When in standalone mode Juju ensures a single Spark master is appointed.\n The status of the unit acting as master reads \"ready (standalone - master)\",\n while the rest of the units display a status of  \"ready (standalone)\".\n In case you remove the master unit Juju will appoint a new master to the cluster.\n However, should a master fail in this standalone mode running jobs and job history\n will be lost.\n\n * **Standalone HA**\n\n To enable High Availability properties of a cluster you need to add a relation\n between spark and a zookeeper deployment. For instance:\n\n    juju deploy apache-zookeeper zookeeper\n    juju add-relation spark zookeeper\n\n In this mode again you can scale your cluster to match your needs by adding/removing\n units. Spark units report \"ready (standalone HA)\" in their status so if you need to\n identify the node acting as master you need to query the Zookeeper deployment.\n\n    juju ssh zk/0\n    zkCli.sh\n    get /spark/master_status\n\n * **Yarn-client and Yarn-cluster**\n\n This charm leverages our pluggable Hadoop model with the `hadoop-plugin`\n interface. This means that you can relate this charm to a base Apache Hadoop cluster\n to run Spark jobs there. The suggested deployment method is to use the\n [hadoop-processing](https://jujucharms.com/hadoop-processing/)\n bundle and add a relation between spark and the plugin:\n\n    juju deploy hadoop-processing\n    juju add-relation plugin spark\n\n\nNote: To transition among execution modes you need to set the\n`spark_execution_mode` config variable:\n\n    juju set spark spark_execution_mode=<new_mode>\n\n## Usage\n\nOnce deployment is complete, you can manually load and run Spark batch or\nstreaming jobs in a variety of ways:\n\n  * **Spark shell**\n\nSpark’s shell provides a simple way to learn the API, as well as a powerful\ntool to analyse data interactively. It is available in either Scala or Python\nand can be run from the Spark unit as follows:\n\n       juju ssh spark/0\n       spark-shell # for interaction using scala\n       pyspark     # for interaction using python\n\n  * **Command line**\n\nSSH to the Spark unit and manually run a spark-submit job, for example:\n\n       juju ssh spark/0\n       spark-submit --class org.apache.spark.examples.SparkPi \\\n        --master yarn-client /usr/lib/spark/lib/spark-examples*.jar 10\n\n  * **Apache Zeppelin visual service**\n\nDeploy Apache Zeppelin and relate it to the Spark unit:\n\n    juju deploy apache-zeppelin zeppelin\n    juju add-relation spark zeppelin\n\nOnce the relation has been made, access the web interface at\n`http://{spark_unit_ip_address}:9090`\n\n  * **IPyNotebook for Spark**\n\nThe IPython Notebook is an interactive computational environment, in which you\ncan combine code execution, rich text, mathematics, plots and rich media.\nDeploy IPython Notebook for Spark and relate it to the Spark unit:\n\n    juju deploy apache-spark-notebook notebook\n    juju add-relation spark notebook\n\nOnce the relation has been made, access the web interface at\n`http://{spark_unit_ip_address}:8880`\n\n\n## Configuration\n\n### `spark_bench_enabled`\n\nInstall the SparkBench benchmarking suite. If `true` (the default), this charm\nwill download spark bench from the URL specified by `spark_bench_ppc64le`\nor `spark_bench_x86_64`, depending on the unit's architecture.\n\n### `spark_execution_mode`\n\nSpark has four modes of execution: local, standalone, yarn-client, and\nyarn-cluster. The default mode is `yarn-client` and can be changed by setting\nthe `spark_execution_mode` config variable.\n\n  * **Local**\n\n    In Local mode, Spark processes jobs locally without any cluster resources.\n    There are 3 ways to specify 'local' mode:\n\n    * `local`\n\n      Run Spark locally with one worker thread (i.e. no parallelism at all).\n\n    * `local[K]`\n\n      Run Spark locally with K worker threads (ideally, set this to the number\n      of cores on your machine).\n\n    * `local[*]`\n\n      Run Spark locally with as many worker threads as logical cores on your\n      machine.\n\n  * **Standalone**\n\n    In `standalone` mode, Spark launches a Master and Worker daemon on the Spark\n    unit. This mode is useful for simulating a distributed cluster environment\n    without actually setting up a cluster.\n\n  * **YARN-client**\n\n    In `yarn-client` mode, the driver runs in the client process, and the\n    application master is only used for requesting resources from YARN.\n\n  * **YARN-cluster**\n\n    In `yarn-cluster` mode, the Spark driver runs inside an application master\n    process which is managed by YARN on the cluster, and the client can go away\n    after initiating the application.\n\n\n## Verify the deployment\n\n### Status and Smoke Test\n\nThe services provide extended status reporting to indicate when they are ready:\n\n    juju status --format=tabular\n\nThis is particularly useful when combined with `watch` to track the on-going\nprogress of the deployment:\n\n    watch -n 0.5 juju status --format=tabular\n\nThe message for each unit will provide information about that unit's state.\nOnce they all indicate that they are ready, you can perform a \"smoke test\"\nto verify that Spark is working as expected using the built-in `smoke-test`\naction:\n\n    juju run-action spark/0 smoke-test\n\n_**Note**: The above assumes Juju 2.0 or greater. If using an earlier version\nof Juju, the syntax is `juju action do spark/0 smoke-test`._\n\n\nAfter a minute or so, you can check the results of the smoke test:\n\n    juju show-action-status\n\n_**Note**: The above assumes Juju 2.0 or greater. If using an earlier version\nof Juju, the syntax is `juju action status`._\n\nYou will see `status: completed` if the smoke test was successful, or\n`status: failed` if it was not.  You can get more information on why it failed\nvia:\n\n    juju show-action-output <action-id>\n\n_**Note**: The above assumes Juju 2.0 or greater. If using an earlier version\nof Juju, the syntax is `juju action fetch <action-id>`._\n\n\n### Verify Job History\n\nThe Job History server shows all active and finished spark jobs submitted.\nTo view the Job History server you need to expose spark (`juju expose spark`)\nand navigate to `http://{spark_master_unit_ip_address}:18080` of the\nunit acting as master.\n\n\n## Benchmarking\n\nThis charm provides several benchmarks, including the\n[Spark Bench](https://github.com/SparkTC/spark-bench) benchmarking\nsuite (if enabled), to gauge the performance of your environment.\n\nThe easiest way to run the benchmarks on this service is to relate it to the\n[Benchmark GUI][].  You will likely also want to relate it to the\n[Benchmark Collector][] to have machine-level information collected during the\nbenchmark, for a more complete picture of how the machine performed.\n\n[Benchmark GUI]: https://jujucharms.com/benchmark-gui/\n[Benchmark Collector]: https://jujucharms.com/benchmark-collector/\n\nHowever, each benchmark is also an action that can be called manually:\n\n    $ juju action do spark/0 pagerank\n    Action queued with id: 88de9367-45a8-4a4b-835b-7660f467a45e\n    $ juju action fetch --wait 0 88de9367-45a8-4a4b-835b-7660f467a45e\n    results:\n      meta:\n        composite:\n          direction: asc\n          units: secs\n          value: \"77.939000\"\n        raw: |\n          PageRank,2015-12-10-23:41:57,77.939000,71.888079,.922363,0,PageRank-MLlibConfig,,,,,10,12,,200000,4.0,1.3,0.15\n        start: 2015-12-10T23:41:34Z\n        stop: 2015-12-10T23:43:16Z\n      results:\n        duration:\n          direction: asc\n          units: secs\n          value: \"77.939000\"\n        throughput:\n          direction: desc\n          units: x/sec\n          value: \".922363\"\n    status: completed\n    timing:\n      completed: 2015-12-10 23:43:59 +0000 UTC\n      enqueued: 2015-12-10 23:42:10 +0000 UTC\n      started: 2015-12-10 23:42:15 +0000 UTC\n\nValid action names at this time are:\n\n  * logisticregression\n  * matrixfactorization\n  * pagerank\n  * sql\n  * streaming\n  * svdplusplus\n  * svm\n  * trianglecount\n  * sparkpi\n\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n",
  "readme_name": "README.md",
  "gatherbase_origin": "juju-charmstore"
}