{
  "name": "mongodb Juju charm",
  "juju_charm_name": "mongodb",
  "revision": "cs:precise/mongodb-40",
  "latest": true,
  "uris": [
    "https://jujucharms.com/mongodb",
    "https://jujucharms.com/mongodb/precise",
    "https://jujucharms.com/mongodb/precise/40",
    "https://api.jujucharms.com/v5/mongodb",
    "https://api.jujucharms.com/v5/precise/mongodb",
    "https://api.jujucharms.com/v5/precise/mongodb-40"
  ],
  "labels": [
    "Juju charm",
    "databases",
    "Type/Middleware/Runtime/Java",
    "Binding/Provider/HP",
    "Binding/Region/North America/US",
    "Mode/Guide/Video",
    "Mode/Executable/Bundle/Juju Charm",
    "Style/Virtualization Level/Hardware/Network",
    "Type/Devopsware/Deployment/Juju",
    "Type/Infrastructure/Operating System",
    "Type/Middleware/Data Store/Document-oriented/MongoDB"
  ],
  "info_url": "https://jujucharms.com/mongodb",
  "package_url": "https://api.jujucharms.com/v5/precise/mongodb-40/archive",
  "created": "2015-06-17T09:30:53.539Z",
  "updated": "2015-06-17T09:30:53.539Z",
  "description": "An open-source document database, and the leading NoSQL database\n\nMongoDB is a high-performance, open source, schema-free document-\noriented  data store that's easy to deploy, manage and use. It's\nnetwork accessible, written in C++ and offers the following features:\n\n- Collection oriented storage - easy storage of object-style data\n- Full index support, including on inner objects\n- Query profiling\n- Replication and fail-over support\n- Efficient storage of binary data including large\n  objects (e.g. videos)\n- Auto-sharding for cloud-level scalability (Q209)\n  High performance, scalability, and reasonable depth of functionality\n  are the goals for the project.\n",
  "maintainer": {
    "name": "charmers"
  },
  "juju_charm_subordinate": false,
  "juju_charm_series": "precise",
  "juju_charm_owner": "charmers",
  "requires": [
    {
      "kind": "host",
      "label": "Infrastructure/Operating System/Linux/Ubuntu",
      "version": "= precise"
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/mongodb",
      "self_resolve": true,
      "juju_interface": "mongodb",
      "juju_name": "mongos",
      "juju_role": "requirer",
      "juju_limit": 1
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/shard",
      "self_resolve": true,
      "juju_interface": "shard",
      "juju_name": "mongos-cfg",
      "juju_role": "requirer",
      "juju_limit": 1
    }
  ],
  "parameters": {
    "arbiter": {
      "type": "string",
      "description": "Enable arbiter mode. Possible values are 'disabled' for no arbiter, 'enable' to become an arbiter or 'host:port' to declare another host as an arbiter.  replicaset_master must be set for this option to work.",
      "default": "disabled",
      "mapping": "charm_option"
    },
    "auth": {
      "type": "boolean",
      "description": "Turn on/off security",
      "default": false,
      "mapping": "charm_option"
    },
    "autoresync": {
      "type": "boolean",
      "description": "Automatically resync if slave data is stale",
      "default": false,
      "mapping": "charm_option"
    },
    "backup_copies_kept": {
      "type": "int",
      "description": "Number of backups to keep. Keeps one week's worth by default.",
      "default": 7,
      "mapping": "charm_option"
    },
    "backup_directory": {
      "type": "string",
      "description": "Where can the backups be found.",
      "default": "/home/ubuntu/backups",
      "mapping": "charm_option"
    },
    "backups_enabled": {
      "type": "boolean",
      "description": "Enable daily backups to disk.",
      "default": false,
      "mapping": "charm_option"
    },
    "bind_ip": {
      "type": "string",
      "description": "IP address that mongodb should listen for connections.",
      "default": "all",
      "mapping": "charm_option"
    },
    "config_server_dbpath": {
      "type": "string",
      "description": "The path where the config server data files will be kept.",
      "default": "/mnt/var/lib/mongodb/configsvr",
      "mapping": "charm_option"
    },
    "config_server_logpath": {
      "type": "string",
      "description": "The path where to send config server log data.",
      "default": "/mnt/var/log/mongodb/configsvr.log",
      "mapping": "charm_option"
    },
    "config_server_port": {
      "type": "int",
      "description": "Port number to use for the config-server",
      "default": 27019,
      "mapping": "charm_option"
    },
    "cpu": {
      "type": "boolean",
      "description": "Enables periodic logging of CPU utilization and I/O wait",
      "default": false,
      "mapping": "charm_option"
    },
    "dbpath": {
      "type": "string",
      "description": "The path where the data files will be kept.",
      "default": "/var/lib/mongodb",
      "mapping": "charm_option"
    },
    "diaglog": {
      "type": "int",
      "description": "Set oplogging level where n is 0=off (default), 1=W, 2=R, 3=both, 7=W+some reads",
      "default": 0,
      "mapping": "charm_option"
    },
    "extra_config_options": {
      "type": "string",
      "description": "Extra options ( comma separated ) to be included ( at the end ) in the mongodb.conf file.",
      "default": "none",
      "mapping": "charm_option"
    },
    "extra_daemon_options": {
      "type": "string",
      "description": "Extra options ( exactly as you would type them in the command line ) to be added via the command line to the mongodb daemon",
      "default": "none",
      "mapping": "charm_option"
    },
    "journal": {
      "type": "boolean",
      "description": "Enable journaling, http://www.mongodb.org/display/DOCS/Journaling",
      "default": true,
      "mapping": "charm_option"
    },
    "key": {
      "type": "string",
      "description": "Key ID to import to the apt keyring to support use with arbitary source configuration from outside of Launchpad archives or PPA's.\n",
      "default": null,
      "mapping": "charm_option"
    },
    "logappend": {
      "type": "boolean",
      "description": "Append log entries to existing log file",
      "default": true,
      "mapping": "charm_option"
    },
    "logpath": {
      "type": "string",
      "description": "The path where to send log data.",
      "default": "/var/log/mongodb/mongodb.log",
      "mapping": "charm_option"
    },
    "logrotate-frequency": {
      "type": "string",
      "description": "How often should the logs be rotated. Use values from logrotate.",
      "default": "daily",
      "mapping": "charm_option"
    },
    "logrotate-maxsize": {
      "type": "string",
      "description": "Maximum log size before rotating.",
      "default": "500M",
      "mapping": "charm_option"
    },
    "logrotate-rotate": {
      "type": "int",
      "description": "Number of log files to keep.",
      "default": 5,
      "mapping": "charm_option"
    },
    "master": {
      "type": "string",
      "description": "Who is the master DB. If not \"self\", put the Master DB here as \"host:port\"",
      "default": "self",
      "mapping": "charm_option"
    },
    "mms-interval": {
      "type": "string",
      "description": "Ping interval for Mongo monitoring server ( in number of seconds )",
      "default": "disabled",
      "mapping": "charm_option"
    },
    "mms-name": {
      "type": "string",
      "description": "Server name for Mongo monitoring server",
      "default": "disabled",
      "mapping": "charm_option"
    },
    "mms-token": {
      "type": "string",
      "description": "Accout token for Mongo monitoring server",
      "default": "disabled",
      "mapping": "charm_option"
    },
    "mongos_logpath": {
      "type": "string",
      "description": "The path where to send log data from the mongo router.",
      "default": "/mnt/var/log/mongodb/mongos.log",
      "mapping": "charm_option"
    },
    "mongos_port": {
      "type": "int",
      "description": "Port number to use for the mongo router",
      "default": 27021,
      "mapping": "charm_option"
    },
    "nocursors": {
      "type": "boolean",
      "description": "Diagnostic/debugging option",
      "default": false,
      "mapping": "charm_option"
    },
    "nohints": {
      "type": "boolean",
      "description": "Ignore query hints",
      "default": false,
      "mapping": "charm_option"
    },
    "noprealloc": {
      "type": "boolean",
      "description": "Disable data file preallocation",
      "default": false,
      "mapping": "charm_option"
    },
    "noscripting": {
      "type": "boolean",
      "description": "Turns off server-side scripting.  This will result in greatly limited functionality",
      "default": false,
      "mapping": "charm_option"
    },
    "notablescan": {
      "type": "boolean",
      "description": "Turns off table scans.  Any query that would do a table scan fails",
      "default": false,
      "mapping": "charm_option"
    },
    "nssize": {
      "type": "string",
      "description": "Specify .ns file size for new databases",
      "default": "default",
      "mapping": "charm_option"
    },
    "objcheck": {
      "type": "boolean",
      "description": "Inspect all client data for validity on receipt (useful for developing drivers)",
      "default": false,
      "mapping": "charm_option"
    },
    "opIdMem": {
      "type": "string",
      "description": "Size limit for in-memory storage of op ids",
      "default": "default",
      "mapping": "charm_option"
    },
    "oplogSize": {
      "type": "string",
      "description": "Custom size for replication operation log",
      "default": "default",
      "mapping": "charm_option"
    },
    "port": {
      "type": "int",
      "description": "Default MongoDB port",
      "default": 27017,
      "mapping": "charm_option"
    },
    "quota": {
      "type": "boolean",
      "description": "Enable db quota management",
      "default": false,
      "mapping": "charm_option"
    },
    "replicaset": {
      "type": "string",
      "description": "Name of the replica set",
      "default": "myset",
      "mapping": "charm_option"
    },
    "replicaset_master": {
      "type": "string",
      "description": "Replica Set master (optional). Possible values are 'auto' for automatic detection based on install time or 'host:port' to connect to 'host' on 'port' and register as a member.",
      "default": "auto",
      "mapping": "charm_option"
    },
    "source": {
      "type": "string",
      "description": "Optional configuration to support use of additional sources such as:\n  - ppa:myteam/ppa\n  - cloud:precise-proposed/icehouse\n  - http://my.archive.com/ubuntu main\nThe last option should be used in conjunction with the key configuration option.\n",
      "default": "None",
      "mapping": "charm_option"
    },
    "verbose": {
      "type": "boolean",
      "description": "Verbose logging output",
      "default": false,
      "mapping": "charm_option"
    },
    "volume-dev-regexp": {
      "type": "string",
      "description": "Deprecated, use the storage subordinate. Block device for attached volumes as seen by the VM, will be \"scanned\" for an unused device when \"volume-map\" is valid for the unit.\n",
      "default": "/dev/vd[b-z]",
      "mapping": "charm_option"
    },
    "volume-ephemeral-storage": {
      "type": "boolean",
      "description": "Deprecated, use the storage subordinate. If false, a configure-error state will be raised if\n   volume-map[$JUJU_UNIT_NAME] is not set (see \"volume-map\"\n   below) - see \"volume-map\" below.\nIf true, service units won't try to use \"volume-map\" (and\n   related variables) to mount and use external (EBS) volumes,\n   thus storage lifetime will equal VM, thus ephemeral.\n   YOU'VE BEEN WARNED.\n",
      "default": true,
      "mapping": "charm_option"
    },
    "volume-map": {
      "type": "string",
      "description": "Deprecated, use the storage subordinate. YAML map as e.g. \"{ mongodb/0: vol-0000010, mongodb/1: vol-0000016 }\". Service units will raise a \"configure-error\" condition if no volume-map value is set for it - it expects a human to set it properly to resolve it.\n",
      "default": "",
      "mapping": "charm_option"
    },
    "web_admin_ui": {
      "type": "boolean",
      "description": "Replica Set Admin UI (accessible via default_port + 1000)",
      "default": true,
      "mapping": "charm_option"
    }
  },
  "provides": [
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/shard",
      "juju_interface": "shard",
      "juju_name": "configsvr",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/block-storage",
      "juju_interface": "block-storage",
      "juju_name": "data",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/mongodb",
      "juju_interface": "mongodb",
      "juju_name": "database",
      "juju_role": "provider",
      "juju_limit": 0
    }
  ],
  "juju_peers": {
    "replica-set": {
      "Name": "replica-set",
      "Role": "peer",
      "Interface": "mongodb-replica-set",
      "Optional": false,
      "Limit": 1,
      "Scope": "global"
    }
  },
  "license": "# Overview\n\nThis charm deploys [MongoDB](http://mongodb.org) in three configurations:\n\n- Single node\n- Replica set\n- Sharded clusters\n\n# Usage\n\n## Review the configurable options\n\nThe MongoDB charm allows for certain values to be configurable via a config.yaml file. The options provided are extensive, you should [review the options](https://jujucharms.com/fullscreen/search/precise/mongodb-20/?text=mongodb#bws-configuration). \n\nSpecifically the following options are important: \n\n- replicaset\n   - ie: myreplicaset\n   - Each replicaset has a unique name to distinguish it’s members from other replicasets available in the network.\n   - The default value of myset should be fine for most single cluster scenarios.\n\n- web_admin_ui\n   - MongoDB comes with a basic but very informative web user interface that provides health\n     and status information on the database node as well as the cluster.\n   - The default value of yes will start the Admin web UI on port 28017.\n\n- replicaset_master\n   - If this node is going to be joining an existing replicaset, you can specify a member of that cluster\n     ( preferably the master node ) so we can join the existing replicaset.\n   - The value should be in the form of host[:port]\n   - ie:  hostname ( will connect to hostname on the default port of 27017 )\n   - ie:  hostname:port  ( will connect to hostname on port number <port> )\n\nMost of the options in config.yaml have been modeled after the default configuration file for mongodb (normally in /etc/mongodb.conf) and should be familiar to most mongodb admins.  Each option in this charm have a brief description of what it does.\n\n# Usage\n\n## Single Node\n\nDeploy the first MongoDB instance\n\n    juju deploy mongodb\n    juju expose mongodb\n\n## Replica Sets\n\nDeploy the first MongoDB instance\n\n    juju deploy mongodb\n    juju expose mongodb\n\nYour deployment should look similar to this ( `juju status` ):\n\n    environment: amazon\n    machines:\n      \"0\":\n        agent-state: started\n        agent-version: 1.16.5\n        dns-name: ec2-184-73-7-172.compute-1.amazonaws.com\n        instance-id: i-cb55cceb\n        instance-state: running\n        series: precise\n        hardware: arch=amd64 cpu-cores=1 cpu-power=100 mem=1740M root-disk=8192M\n      \"1\":\n        agent-state: pending\n        dns-name: ec2-54-196-181-161.compute-1.amazonaws.com\n        instance-id: i-974bd2b7\n        instance-state: pending\n        series: precise\n        hardware: arch=amd64 cpu-cores=1 cpu-power=100 mem=1740M root-disk=8192M\n    services:\n      mongodb:\n        charm: cs:precise/mongodb-20\n        exposed: false\n        relations:\n          replica-set:\n          - mongodb\n        units:\n          mongodb/0:\n            agent-state: pending\n            machine: \"1\"\n            public-address: ec2-54-196-181-161.compute-1.amazonaws.com\n\n\nIn addition, the MongoDB web interface should also be accessible via the services’\npublic-address and port 28017 ( ie: http://ec2-50-17-73-255.compute-1.amazonaws.com:28017 ).\n\n### (Optional) Change the replicaset name\n\n    juju set mongodb replicaset=<new_replicaset_name>\n\n### Add one more nodes to your replicaset\n\n    juju add-unit mongodb\n\n\n### Add multiple nodes to your replicaset\n\n    juju add-unit mongodb -n5\n\n\nWe now have a working MongoDB replica-set.\n\n## Sharding (Scale Out Usage)\n\nAccording the the MongoDB documentation found on [their website](http://docs.mongodb.org/manual/tutorial/deploy-shard-cluster/), one way of deploying a Shard Cluster is as follows:\n\n- deploy config servers\n- deploy a mongo shell (mongos)\n- deploy shards\n- connect the config servers to the mongo shell\n- add the shards to the mongo shell\n\nUsing Juju we can deploy a sharded cluster using the following commands:\n\n### Prepare a configuration file similar to the following:\n\n    shard1:\n      replicaset: shard1\n    shard2:\n      replicaset: shard2\n    shard3:\n      replicaset: shard3\n    configsvr:\n      replicaset: configsvr\n\nWe'll save this one as `~/mongodb-shard.yaml`.\n  \n### Bootstrap the environment\n    juju bootstrap\n\n### Config Servers ( we'll deploy 3 of them )\n    juju deploy mongodb configsvr --config ~/mongodb-shard.yaml -n3\n\n### Mongo Shell ( We just deploy one for now )\n    juju deploy mongodb mongos\n\n### Shards ( We'll deploy three replica-sets )\n    juju deploy mongodb shard1 --config ~/mongodb-shard.yaml -n3\n    juju deploy mongodb shard2 --config ~/mongodb-shard.yaml -n3\n    juju deploy mongodb shard3 --config ~/mongodb-shard.yaml -n3\n\n### Connect the Config Servers to the Mongo shell (mongos)\n\n    juju add-relation mongos:mongos-cfg configsvr:configsvr\n\n### Connect each Shard to the Mongo shell (mongos)\n\n    juju add-relation mongos:mongos shard1:database\n    juju add-relation mongos:mongos shard2:database\n    juju add-relation mongos:mongos shard3:database\n\nWith the above commands, we should now have a three replica-set sharded cluster running.\nUsing the default configuration, here are some details of our sharded cluster:\n\n- mongos is running on port 27021\n- configsvr is running on port 27019\n- the shards are running on the default mongodb port of 27017\n- The web admin is turned on by default and accessible with your browser on port 28017 on each of the shards.\n\nTo verify that your sharded cluster is running, connect to the mongo shell and run `sh.status()`:\n\n- `mongo --host <mongos_host>:<mongos_port>`\n- `run sh.status()`\nYou should see your the hosts for your shards in the status output.\n\n### Use the storage subordinate to store mongodb data on a permanent OpenStack or Amazon EBS volume\n\nThe [storage](http://manage.jujucharms.com/charms/precise/storage) subordinate and [block-storage-broker](http://manage.jujucharms.com/charms/precise/block-storage-broker) service can automatically handle attaching the volume and mounting it to the unit before MongoDB is setup to use it.\n\nFor example if you've created the volumes `vol-id-00001` and `vol-id-00002` and want to attach them to your 2 mongo units, with your OpenStack or AWS credentials in a `credential.yaml` file:\n\n    juju deploy block-storage-broker --config credentials.yaml\n    juju deploy storage\n    juju add-relation block-storage-broker storage\n    juju set storage provider=block-storage-broker\n    juju set volume_map=\"{mongodb/0: vol-id-00001, mongodb/1: vol-id-00002}\"\n    juju add-relation storage mongodb\n\n\n### Use a permanent Openstack volume to store mongodb data. (DEPRECATED)\n\n**Note**: Although these steps will still work they are now deprecated, you should use the storage subordinate above instead.\n\nTo deploy mongodb using permanent volume on Openstack, the permanent volume should be attached to the mongodb unit just after the deployment, then the configuration should be updated like follows.\n\n    juju set mongodb volume-dev-regexp=\"/dev/vdc\" volume-map='{\"mongodb/0\": \"vol-id-00000000000000\"}' volume-ephemeral-storage=false\n\n### Backups\n\nBackups can be enabled via config. Note that destroying the service cannot\ncurrently remove the backup cron job so it will continue to run. There is a\nsetting for the number of backups to keep, however, to prevent from filling\ndisk space.\n\nTo fetch the backups scp the files down from the path in the config.\n\n## Known Limitations and Issues\n\n- If your master/slave/replicaset deployment is not updating correctly, check the log files at `/var/log/mongodb/mongodb.log` to see if there is an obvious reason ( port not open etc.).\n- Ensure that TCP port 27017 is accessible from all of the nodes in the deployment.\n- If you are trying to access your MongoDB instance from outside your deployment, ensure that the service has been exposed ( `juju expose mongodb` )\n- Make sure that the mongod process is running ( ps -ef | grep mongo ).\n- Try restarting the database ( restart mongodb )\n- If all else fails, remove the data directory on the slave ( `rm -fr /var/log/mongodb/data/*` ) and restart the mongodb-slave daemon ( `restart mongodb` ).\n\n# Contact Information\n\n## MongoDB Contact Information\n\n- [MongoDB website](http://mongodb.org) \n- [MongoDB documentation](http://www.mongodb.org/display/DOCS/Home)\n- [MongoDB bug tracker](https://jira.mongodb.org/secure/Dashboard.jspa)\n- [MongoDB user mailing list](https://groups.google.com/forum/#!forum/mongodb-user)\n",
  "readme": "# Overview\n\nThis charm deploys [MongoDB](http://mongodb.org) in three configurations:\n\n- Single node\n- Replica set\n- Sharded clusters\n\n# Usage\n\n## Review the configurable options\n\nThe MongoDB charm allows for certain values to be configurable via a config.yaml file. The options provided are extensive, you should [review the options](https://jujucharms.com/fullscreen/search/precise/mongodb-20/?text=mongodb#bws-configuration). \n\nSpecifically the following options are important: \n\n- replicaset\n   - ie: myreplicaset\n   - Each replicaset has a unique name to distinguish it’s members from other replicasets available in the network.\n   - The default value of myset should be fine for most single cluster scenarios.\n\n- web_admin_ui\n   - MongoDB comes with a basic but very informative web user interface that provides health\n     and status information on the database node as well as the cluster.\n   - The default value of yes will start the Admin web UI on port 28017.\n\n- replicaset_master\n   - If this node is going to be joining an existing replicaset, you can specify a member of that cluster\n     ( preferably the master node ) so we can join the existing replicaset.\n   - The value should be in the form of host[:port]\n   - ie:  hostname ( will connect to hostname on the default port of 27017 )\n   - ie:  hostname:port  ( will connect to hostname on port number <port> )\n\nMost of the options in config.yaml have been modeled after the default configuration file for mongodb (normally in /etc/mongodb.conf) and should be familiar to most mongodb admins.  Each option in this charm have a brief description of what it does.\n\n# Usage\n\n## Single Node\n\nDeploy the first MongoDB instance\n\n    juju deploy mongodb\n    juju expose mongodb\n\n## Replica Sets\n\nDeploy the first MongoDB instance\n\n    juju deploy mongodb\n    juju expose mongodb\n\nYour deployment should look similar to this ( `juju status` ):\n\n    environment: amazon\n    machines:\n      \"0\":\n        agent-state: started\n        agent-version: 1.16.5\n        dns-name: ec2-184-73-7-172.compute-1.amazonaws.com\n        instance-id: i-cb55cceb\n        instance-state: running\n        series: precise\n        hardware: arch=amd64 cpu-cores=1 cpu-power=100 mem=1740M root-disk=8192M\n      \"1\":\n        agent-state: pending\n        dns-name: ec2-54-196-181-161.compute-1.amazonaws.com\n        instance-id: i-974bd2b7\n        instance-state: pending\n        series: precise\n        hardware: arch=amd64 cpu-cores=1 cpu-power=100 mem=1740M root-disk=8192M\n    services:\n      mongodb:\n        charm: cs:precise/mongodb-20\n        exposed: false\n        relations:\n          replica-set:\n          - mongodb\n        units:\n          mongodb/0:\n            agent-state: pending\n            machine: \"1\"\n            public-address: ec2-54-196-181-161.compute-1.amazonaws.com\n\n\nIn addition, the MongoDB web interface should also be accessible via the services’\npublic-address and port 28017 ( ie: http://ec2-50-17-73-255.compute-1.amazonaws.com:28017 ).\n\n### (Optional) Change the replicaset name\n\n    juju set mongodb replicaset=<new_replicaset_name>\n\n### Add one more nodes to your replicaset\n\n    juju add-unit mongodb\n\n\n### Add multiple nodes to your replicaset\n\n    juju add-unit mongodb -n5\n\n\nWe now have a working MongoDB replica-set.\n\n## Sharding (Scale Out Usage)\n\nAccording the the MongoDB documentation found on [their website](http://docs.mongodb.org/manual/tutorial/deploy-shard-cluster/), one way of deploying a Shard Cluster is as follows:\n\n- deploy config servers\n- deploy a mongo shell (mongos)\n- deploy shards\n- connect the config servers to the mongo shell\n- add the shards to the mongo shell\n\nUsing Juju we can deploy a sharded cluster using the following commands:\n\n### Prepare a configuration file similar to the following:\n\n    shard1:\n      replicaset: shard1\n    shard2:\n      replicaset: shard2\n    shard3:\n      replicaset: shard3\n    configsvr:\n      replicaset: configsvr\n\nWe'll save this one as `~/mongodb-shard.yaml`.\n  \n### Bootstrap the environment\n    juju bootstrap\n\n### Config Servers ( we'll deploy 3 of them )\n    juju deploy mongodb configsvr --config ~/mongodb-shard.yaml -n3\n\n### Mongo Shell ( We just deploy one for now )\n    juju deploy mongodb mongos\n\n### Shards ( We'll deploy three replica-sets )\n    juju deploy mongodb shard1 --config ~/mongodb-shard.yaml -n3\n    juju deploy mongodb shard2 --config ~/mongodb-shard.yaml -n3\n    juju deploy mongodb shard3 --config ~/mongodb-shard.yaml -n3\n\n### Connect the Config Servers to the Mongo shell (mongos)\n\n    juju add-relation mongos:mongos-cfg configsvr:configsvr\n\n### Connect each Shard to the Mongo shell (mongos)\n\n    juju add-relation mongos:mongos shard1:database\n    juju add-relation mongos:mongos shard2:database\n    juju add-relation mongos:mongos shard3:database\n\nWith the above commands, we should now have a three replica-set sharded cluster running.\nUsing the default configuration, here are some details of our sharded cluster:\n\n- mongos is running on port 27021\n- configsvr is running on port 27019\n- the shards are running on the default mongodb port of 27017\n- The web admin is turned on by default and accessible with your browser on port 28017 on each of the shards.\n\nTo verify that your sharded cluster is running, connect to the mongo shell and run `sh.status()`:\n\n- `mongo --host <mongos_host>:<mongos_port>`\n- `run sh.status()`\nYou should see your the hosts for your shards in the status output.\n\n### Use the storage subordinate to store mongodb data on a permanent OpenStack or Amazon EBS volume\n\nThe [storage](http://manage.jujucharms.com/charms/precise/storage) subordinate and [block-storage-broker](http://manage.jujucharms.com/charms/precise/block-storage-broker) service can automatically handle attaching the volume and mounting it to the unit before MongoDB is setup to use it.\n\nFor example if you've created the volumes `vol-id-00001` and `vol-id-00002` and want to attach them to your 2 mongo units, with your OpenStack or AWS credentials in a `credential.yaml` file:\n\n    juju deploy block-storage-broker --config credentials.yaml\n    juju deploy storage\n    juju add-relation block-storage-broker storage\n    juju set storage provider=block-storage-broker\n    juju set volume_map=\"{mongodb/0: vol-id-00001, mongodb/1: vol-id-00002}\"\n    juju add-relation storage mongodb\n\n\n### Use a permanent Openstack volume to store mongodb data. (DEPRECATED)\n\n**Note**: Although these steps will still work they are now deprecated, you should use the storage subordinate above instead.\n\nTo deploy mongodb using permanent volume on Openstack, the permanent volume should be attached to the mongodb unit just after the deployment, then the configuration should be updated like follows.\n\n    juju set mongodb volume-dev-regexp=\"/dev/vdc\" volume-map='{\"mongodb/0\": \"vol-id-00000000000000\"}' volume-ephemeral-storage=false\n\n### Backups\n\nBackups can be enabled via config. Note that destroying the service cannot\ncurrently remove the backup cron job so it will continue to run. There is a\nsetting for the number of backups to keep, however, to prevent from filling\ndisk space.\n\nTo fetch the backups scp the files down from the path in the config.\n\n## Known Limitations and Issues\n\n- If your master/slave/replicaset deployment is not updating correctly, check the log files at `/var/log/mongodb/mongodb.log` to see if there is an obvious reason ( port not open etc.).\n- Ensure that TCP port 27017 is accessible from all of the nodes in the deployment.\n- If you are trying to access your MongoDB instance from outside your deployment, ensure that the service has been exposed ( `juju expose mongodb` )\n- Make sure that the mongod process is running ( ps -ef | grep mongo ).\n- Try restarting the database ( restart mongodb )\n- If all else fails, remove the data directory on the slave ( `rm -fr /var/log/mongodb/data/*` ) and restart the mongodb-slave daemon ( `restart mongodb` ).\n\n# Contact Information\n\n## MongoDB Contact Information\n\n- [MongoDB website](http://mongodb.org) \n- [MongoDB documentation](http://www.mongodb.org/display/DOCS/Home)\n- [MongoDB bug tracker](https://jira.mongodb.org/secure/Dashboard.jspa)\n- [MongoDB user mailing list](https://groups.google.com/forum/#!forum/mongodb-user)\n",
  "readme_name": "README.md",
  "gatherbase_origin": "juju-charmstore"
}