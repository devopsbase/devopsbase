{
  "name": "gobblin Juju charm",
  "juju_charm_name": "gobblin",
  "revision": "cs:trusty/gobblin-0",
  "latest": true,
  "uris": [
    "https://jujucharms.com/gobblin",
    "https://jujucharms.com/gobblin/trusty",
    "https://jujucharms.com/gobblin/trusty/0",
    "https://api.jujucharms.com/v5/gobblin",
    "https://api.jujucharms.com/v5/trusty/gobblin",
    "https://api.jujucharms.com/v5/trusty/gobblin-0"
  ],
  "labels": [
    "Juju charm",
    "bigdata",
    "hadoop",
    "Mode/Executable/Bundle/Juju Charm",
    "Mode/API/Toolkit",
    "Type/Devopsware/Version Control/Git",
    "Type/Devopsware/Deployment/Juju",
    "Type/Middleware/Data Store",
    "Type/Middleware/Data Processing/Hadoop"
  ],
  "info_url": "https://jujucharms.com/gobblin",
  "package_url": "https://api.jujucharms.com/v5/trusty/gobblin-0/archive",
  "created": "2016-05-23T15:17:37.021Z",
  "updated": "2016-05-23T15:17:37.021Z",
  "description": "Data ingestion framework built on top of Hadoop\n\nGobblin is a universal data ingestion framework for extracting,\ntransforming, and loading large volume of data from a variety of data\nsources, e.g., databases, rest APIs, FTP/SFTP servers, filers, etc., onto Hadoop.\n\nLearn more at http://https://github.com/linkedin/gobblin/wiki\n",
  "maintainer": {
    "name": "bigdata-charmers"
  },
  "juju_charm_subordinate": false,
  "juju_charm_series": "trusty",
  "juju_charm_owner": "bigdata-charmers",
  "requires": [
    {
      "kind": "host",
      "label": "Infrastructure/Operating System/Linux/Ubuntu",
      "version": "= trusty"
    }
  ],
  "provides": [
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/hadoop-plugin",
      "juju_interface": "hadoop-plugin",
      "juju_name": "hadoop",
      "juju_role": "provider",
      "juju_limit": 0
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/provides/java",
      "juju_interface": "java",
      "juju_name": "java",
      "juju_role": "provider",
      "juju_limit": 0
    }
  ],
  "license": "## Overview\n\n\"Gobblin is a universal data ingestion framework for extracting, transforming,\nand loading large volume of data from a variety of data sources, \ne.g., databases, rest APIs, FTP/SFTP servers, filers, etc., onto Hadoop.\"\nfrom the [Gobblin wiki](https://github.com/linkedin/gobblin/wiki) \n\n## Usage\nThis charm is uses the Hadoob base layer and the HDFS interface to pull its dependencies\nand act as a client to a Hadoop namenode. Here is how to deploy the Hadoop infrastructure:\n\n    juju quickstart apache-processing-mapreduce\n\nDeploy the Gobblin charm and relate it to tha neme node:\n \n    juju deploy gobblin\n    juju add-relation gobblin plugin\n\n\n## Testing the deployment\n\n### Smoke test Gobblin\nFrom the Gobblin unit, start the wikipedia ingestion demo job as the `gobblin` user:\n\n    juju ssh gobblin/0\n    cd /tmp\n    sudo su gobblin -c \"gobblin-mapreduce.sh --conf wikipedia.pull --jars /usr/lib/gobblin/lib/gobblin-example.jar\"\n\nThe output will be in hdfs under /user/gobblin/work/job-output/gobblin/example/wikipedia/WikipediaOutput/<Your_Job_Id> .\nYou can set the output directory through the ``--workdir`` flag. \n\nList and get the job output file(s) in avro format.\n\n    hdfs dfs -ls /user/gobblin/work/job-output/gobblin/example/wikipedia/WikipediaOutput/<Your_Job_Id>\n    hdfs dfs -get /user/gobblin/work/job-output/gobblin/example/wikipedia/WikipediaOutput/<Your_Job_Id>/<Path_To_Output>/<Output.avro>\n\nTransform to JSON.\n\n    curl -O http://central.maven.org/maven2/org/apache/avro/avro-tools/1.7.7/avro-tools-1.7.7.jar\n    java -jar avro-tools-1.7.7.jar tojson --pretty <Output.avro> > output.json\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n",
  "readme": "## Overview\n\n\"Gobblin is a universal data ingestion framework for extracting, transforming,\nand loading large volume of data from a variety of data sources, \ne.g., databases, rest APIs, FTP/SFTP servers, filers, etc., onto Hadoop.\"\nfrom the [Gobblin wiki](https://github.com/linkedin/gobblin/wiki) \n\n## Usage\nThis charm is uses the Hadoob base layer and the HDFS interface to pull its dependencies\nand act as a client to a Hadoop namenode. Here is how to deploy the Hadoop infrastructure:\n\n    juju quickstart apache-processing-mapreduce\n\nDeploy the Gobblin charm and relate it to tha neme node:\n \n    juju deploy gobblin\n    juju add-relation gobblin plugin\n\n\n## Testing the deployment\n\n### Smoke test Gobblin\nFrom the Gobblin unit, start the wikipedia ingestion demo job as the `gobblin` user:\n\n    juju ssh gobblin/0\n    cd /tmp\n    sudo su gobblin -c \"gobblin-mapreduce.sh --conf wikipedia.pull --jars /usr/lib/gobblin/lib/gobblin-example.jar\"\n\nThe output will be in hdfs under /user/gobblin/work/job-output/gobblin/example/wikipedia/WikipediaOutput/<Your_Job_Id> .\nYou can set the output directory through the ``--workdir`` flag. \n\nList and get the job output file(s) in avro format.\n\n    hdfs dfs -ls /user/gobblin/work/job-output/gobblin/example/wikipedia/WikipediaOutput/<Your_Job_Id>\n    hdfs dfs -get /user/gobblin/work/job-output/gobblin/example/wikipedia/WikipediaOutput/<Your_Job_Id>/<Path_To_Output>/<Output.avro>\n\nTransform to JSON.\n\n    curl -O http://central.maven.org/maven2/org/apache/avro/avro-tools/1.7.7/avro-tools-1.7.7.jar\n    java -jar avro-tools-1.7.7.jar tojson --pretty <Output.avro> > output.json\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n",
  "readme_name": "README.md",
  "gatherbase_origin": "juju-charmstore"
}