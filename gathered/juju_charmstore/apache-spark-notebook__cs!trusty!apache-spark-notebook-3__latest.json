{
  "name": "apache-spark-notebook Juju charm",
  "juju_charm_name": "apache-spark-notebook",
  "revision": "cs:trusty/apache-spark-notebook-3",
  "latest": true,
  "uris": [
    "https://jujucharms.com/apache-spark-notebook",
    "https://jujucharms.com/apache-spark-notebook/trusty",
    "https://jujucharms.com/apache-spark-notebook/trusty/3",
    "https://api.jujucharms.com/v5/apache-spark-notebook",
    "https://api.jujucharms.com/v5/trusty/apache-spark-notebook",
    "https://api.jujucharms.com/v5/trusty/apache-spark-notebook-3"
  ],
  "labels": [
    "Juju charm",
    "bigdata",
    "hadoop",
    "apache",
    "Type/Middleware/Runtime/Python",
    "Mode/Guide/Text/Book",
    "Mode/Executable/Bundle/Juju Charm",
    "Mode/API",
    "Type/Devopsware/IDE/Web-based",
    "Type/Devopsware/Deployment/Juju",
    "Type/Middleware/Web Server/Apache HTTP Server"
  ],
  "info_url": "https://jujucharms.com/apache-spark-notebook",
  "package_url": "https://api.jujucharms.com/v5/trusty/apache-spark-notebook-3/archive",
  "created": "2016-02-23T20:16:21.841Z",
  "updated": "2016-02-23T20:16:21.841Z",
  "description": "A web-based IPython Notebook for Apache Spark.\n\nThe IPython Notebook is an interactive computational environment, in which\nyou can combine code execution, rich text, mathematics, plots, and rich media.\nIPython Notebook and Sparkâ€™s Python API are a powerful combination for data\nscience.\n",
  "maintainer": {
    "name": "bigdata-charmers"
  },
  "juju_charm_subordinate": true,
  "juju_charm_series": "trusty",
  "juju_charm_owner": "bigdata-charmers",
  "requires": [
    {
      "kind": "host",
      "label": "Infrastructure/Operating System/Linux/Ubuntu",
      "version": "= trusty"
    },
    {
      "kind": "peer",
      "uri": "https://jujucharms.com/requires/spark",
      "self_resolve": true,
      "juju_interface": "spark",
      "juju_name": "spark",
      "juju_role": "requirer",
      "juju_limit": 1
    }
  ],
  "license": "## Overview\n\nIPython Notebook is a web-based notebook that enables interactive data\nanalytics for Spark. The developers of Apache Spark have given thoughtful\nconsideration to Python as a language of choice for data analysis. They have\ndeveloped the PySpark API for working with RDDs in Python, and further support\nusing the powerful IPythonshell instead of the builtin Python REPL.\n\nThe developers of IPython have invested considerable effort in building the\nIPython Notebook, a system inspired by Mathematica that allows you to create\n\"executable documents.\" IPython Notebooks can integrate formatted text\n(Markdown), executable code (Python), mathematical formulae (LaTeX), and\ngraphics/visualizations (matplotlib) into a single document that captures the\nflow of an exploration and can be exported as a formatted report or an\nexecutable script.\n\n\n## Usage\n\nThis is a subordinate charm that requires the `apache-spark` interface. This\nmeans that you will need to deploy a base Apache Spark cluster to use\nIPython Notebook. An easy way to deploy the recommended environment is to use\nthe [apache-hadoop-spark-notebook](https://jujucharms.com/apache-hadoop-spark-notebook)\nbundle. This will deploy the Apache Hadoop platform with an Apache Spark +\nIPython Notebook unit that communicates with the cluster by relating to the\n`apache-hadoop-plugin` subordinate charm:\n\n    juju-quickstart apache-hadoop-spark-notebook\n\nAlternatively, you may manually deploy the recommended environment as follows:\n\n    juju deploy apache-hadoop-hdfs-master hdfs-master\n    juju deploy apache-hadoop-yarn-master yarn-master\n    juju deploy apache-hadoop-compute-slave compute-slave\n    juju deploy apache-hadoop-plugin plugin\n    juju deploy apache-spark spark\n    juju deploy apache-spark-notebook notebook\n\n    juju add-relation yarn-master hdfs-master\n    juju add-relation compute-slave yarn-master\n    juju add-relation compute-slave hdfs-master\n    juju add-relation plugin yarn-master\n    juju add-relation plugin hdfs-master\n    juju add-relation spark plugin\n    juju add-relation notebook spark\n\nOnce deployment is complete, expose the notebook service:\n\n    juju expose notebook\n\nYou may now access the web interface at\nhttp://{spark_unit_ip_address}:8880. The ip address can be found by running\n`juju status spark | grep public-address`.\n\n\n## Testing the deployment\n\nFrom the IPython Notebook web interface, click on the \"New Notebook\" button.\nIn the notebook cell type \"sc.\" followed by the \"Tab\" key. The Spark API\ncompletion menu should appear. This verifies the notebook can communicate\nwith the Spark unit.\n\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [IPython Notebook home page](http://ipython.org/notebook.html)\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n- `#juju` on `irc.freenode.net`\n",
  "readme": "## Overview\n\nIPython Notebook is a web-based notebook that enables interactive data\nanalytics for Spark. The developers of Apache Spark have given thoughtful\nconsideration to Python as a language of choice for data analysis. They have\ndeveloped the PySpark API for working with RDDs in Python, and further support\nusing the powerful IPythonshell instead of the builtin Python REPL.\n\nThe developers of IPython have invested considerable effort in building the\nIPython Notebook, a system inspired by Mathematica that allows you to create\n\"executable documents.\" IPython Notebooks can integrate formatted text\n(Markdown), executable code (Python), mathematical formulae (LaTeX), and\ngraphics/visualizations (matplotlib) into a single document that captures the\nflow of an exploration and can be exported as a formatted report or an\nexecutable script.\n\n\n## Usage\n\nThis is a subordinate charm that requires the `apache-spark` interface. This\nmeans that you will need to deploy a base Apache Spark cluster to use\nIPython Notebook. An easy way to deploy the recommended environment is to use\nthe [apache-hadoop-spark-notebook](https://jujucharms.com/apache-hadoop-spark-notebook)\nbundle. This will deploy the Apache Hadoop platform with an Apache Spark +\nIPython Notebook unit that communicates with the cluster by relating to the\n`apache-hadoop-plugin` subordinate charm:\n\n    juju-quickstart apache-hadoop-spark-notebook\n\nAlternatively, you may manually deploy the recommended environment as follows:\n\n    juju deploy apache-hadoop-hdfs-master hdfs-master\n    juju deploy apache-hadoop-yarn-master yarn-master\n    juju deploy apache-hadoop-compute-slave compute-slave\n    juju deploy apache-hadoop-plugin plugin\n    juju deploy apache-spark spark\n    juju deploy apache-spark-notebook notebook\n\n    juju add-relation yarn-master hdfs-master\n    juju add-relation compute-slave yarn-master\n    juju add-relation compute-slave hdfs-master\n    juju add-relation plugin yarn-master\n    juju add-relation plugin hdfs-master\n    juju add-relation spark plugin\n    juju add-relation notebook spark\n\nOnce deployment is complete, expose the notebook service:\n\n    juju expose notebook\n\nYou may now access the web interface at\nhttp://{spark_unit_ip_address}:8880. The ip address can be found by running\n`juju status spark | grep public-address`.\n\n\n## Testing the deployment\n\nFrom the IPython Notebook web interface, click on the \"New Notebook\" button.\nIn the notebook cell type \"sc.\" followed by the \"Tab\" key. The Spark API\ncompletion menu should appear. This verifies the notebook can communicate\nwith the Spark unit.\n\n\n## Contact Information\n\n- <bigdata@lists.ubuntu.com>\n\n\n## Help\n\n- [IPython Notebook home page](http://ipython.org/notebook.html)\n- [Juju mailing list](https://lists.ubuntu.com/mailman/listinfo/juju)\n- [Juju community](https://jujucharms.com/community)\n- `#juju` on `irc.freenode.net`\n",
  "readme_name": "README.md",
  "gatherbase_origin": "juju-charmstore"
}